{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L_001: How to profile CUDA kernels in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At a glance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1 - C++ & Python Kernels\n",
    "\n",
    "Key Terms:\n",
    "\n",
    "- PyTorch `Profiler`\n",
    "- Binding - interfacing or connecting code written in different programming languages.\n",
    "- Numba - a Python library that serves as an interface to craft CUDA kernels using Python syntax.\n",
    "  \n",
    "        -> Unless we have very specific needs that Triton doesn’t cover, its built-in optimizations will usually yield better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba can be used to implement CUDA kernels using Python syntax. It employs slightly different terminology for kernel creation compared to kernels written in C++. Alternatively, we can bind C++ code in our Python script using an inline binding package, which creates a temporary folder where the generated and compiled code is saved. By doing so, it abstracts away the complexity of makefiles and CUDA compiler flags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2 - Triton\n",
    "\n",
    "Key Terms:\n",
    "\n",
    "- Triton – DSL (Domain Specific Language) for Generating PTX\n",
    "- New interperter mode -> `@triton.jit(interpreter=True)` == `TRITON_INTERPRET=1`\n",
    "- **TIP**: Write PyToch program and flag it with `TORCH_LOGS=\"output_code\" python compile_square.py` -> get a Triton Kernel\n",
    "- Most important optimization = Fusions\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 - CUDA Profilers\n",
    "\n",
    "Key Terms:\n",
    "\n",
    "- CUDA profilers\n",
    "  - ncu (Doesn't work on most cloud vendors as they won't give us that profile information)\n",
    "    - Neat visual profiler: `ncu --set full -o output $(which python) train.py`\n",
    "      - Nsight\n",
    "  \n",
    "  - ncu give us actionable hints \n",
    "    - Tail effect + achieved occupacy -< often controlled by things like Padding >- We can control Padding \n",
    "    - Long scoreboard stalls -<memory coalescing, use shared memory >- We can't control (Triton does it for us)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# S1 - C++ & Python Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 4., 9.])\n",
      "tensor([1., 4., 9.])\n",
      "tensor([1., 4., 9.])\n",
      "=============\n",
      "Profiling torch.square\n",
      "=============\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::square         0.37%       6.484us        88.49%       1.544ms       1.544ms       0.000us         0.00%     262.431us     262.431us             1  \n",
      "                                              aten::pow        86.66%       1.512ms        88.11%       1.537ms       1.537ms     262.431us       100.00%     262.431us     262.431us             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     262.431us       100.00%     262.431us     262.431us             1  \n",
      "                                      aten::result_type         0.08%       1.425us         0.08%       1.425us       1.425us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                               aten::to         0.02%       0.327us         0.02%       0.327us       0.327us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                       cudaLaunchKernel         1.36%      23.667us         1.36%      23.667us      23.667us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                  cudaDeviceSynchronize        11.51%     200.905us        11.51%     200.905us     200.905us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.745ms\n",
      "Self CUDA time total: 262.431us\n",
      "\n",
      "=============\n",
      "Profiling a * a\n",
      "=============\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                              aten::mul        86.75%       1.536ms        87.86%       1.556ms       1.556ms     263.684us       100.00%     263.684us     263.684us             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     263.684us       100.00%     263.684us     263.684us             1  \n",
      "                                       cudaLaunchKernel         1.11%      19.662us         1.11%      19.662us      19.662us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                  cudaDeviceSynchronize        12.14%     214.925us        12.14%     214.925us     214.925us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.771ms\n",
      "Self CUDA time total: 263.684us\n",
      "\n",
      "=============\n",
      "Profiling a ** 2\n",
      "=============\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                              aten::pow        86.63%       1.543ms        87.73%       1.562ms       1.562ms     262.596us       100.00%     262.596us     262.596us             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     262.596us       100.00%     262.596us     262.596us             1  \n",
      "                                      aten::result_type         0.05%       0.808us         0.05%       0.808us       0.808us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                               aten::to         0.02%       0.288us         0.02%       0.288us       0.288us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                       cudaLaunchKernel         1.03%      18.400us         1.03%      18.400us      18.400us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                  cudaDeviceSynchronize        12.27%     218.572us        12.27%     218.572us     218.572us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.781ms\n",
      "Self CUDA time total: 262.596us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python pytorch_square.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python pt_profiler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-18 12:32:42.281996: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-18 12:32:42.293486: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739881962.307101 1591562 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739881962.311068 1591562 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-18 12:32:42.324384: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0218 12:32:43.553025 139713981884224 server_ingester.py:290] Server binary (from Python package v0.7.2): /home/alex/miniforge3/envs/gpum/lib/python3.10/site-packages/tensorboard_data_server/bin/server\n",
      "I0218 12:32:43.553357 139713981884224 server_ingester.py:138] Spawning data server: ['/home/alex/miniforge3/envs/gpum/lib/python3.10/site-packages/tensorboard_data_server/bin/server', '--logdir=./log', '--reload=5', '--samples-per-plugin=', '--port=0', '--port-file=/tmp/tensorboard_data_server_ea0ufcrj/port', '--die-after-stdin', '--error-file=/tmp/tensorboard_data_server_ea0ufcrj/startup_error', '--verbose', '--verbose']\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Parsed options: Opts { logdir: \"./log\", host: \"localhost\", port: 0, reload: Loop { delay: 5s }, verbosity: 2, die_after_stdin: true, port_file: Some(\"/tmp/tensorboard_data_server_ea0ufcrj/port\"), error_file: Some(\"/tmp/tensorboard_data_server_ea0ufcrj/startup_error\"), checksum: false, no_checksum: false, samples_per_plugin: PluginSamplingHint({}) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m mio::poll\u001b[0m\u001b[38;5;8m]\u001b[0m registering event source with poller: token=Token(0), interests=READABLE | WRITABLE\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Wrote port \"35131\" to /tmp/tensorboard_data_server_ea0ufcrj/port\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Starting load cycle\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Finished load cycle (66.556µs)\n",
      "I0218 12:32:43.563805 139713981884224 server_ingester.py:160] Polling for data server port (attempt 0)\n",
      "I0218 12:32:43.563954 139713981884224 server_ingester.py:162] Port file contents: '35131\\n'\n",
      "I0218 12:32:43.566846 139713981884224 server_ingester.py:176] Opened channel to data server at pid 1591601 via localhost:35131\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m mio::poll\u001b[0m\u001b[38;5;8m]\u001b[0m registering event source with poller: token=Token(1), interests=READABLE | WRITABLE\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m server_handshake;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m -> server_handshake;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Settings { flags: (0x0), initial_window_size: 1048576, max_frame_size: 16384, max_header_list_size: 16777216 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Settings { flags: (0x0), initial_window_size: 1048576, max_frame_size: 16384, max_header_list_size: 16777216 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::settings\u001b[0m\u001b[38;5;8m]\u001b[0m encoding SETTINGS; len=18\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::settings\u001b[0m\u001b[38;5;8m]\u001b[0m encoding setting; val=InitialWindowSize(1048576)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::settings\u001b[0m\u001b[38;5;8m]\u001b[0m encoding setting; val=MaxFrameSize(16384)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::settings\u001b[0m\u001b[38;5;8m]\u001b[0m encoding setting; val=MaxHeaderListSize(16777216)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m encoded settings rem=27\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m <- server_handshake;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m -> server_handshake;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m state=Flushing(_)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m -> flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m queued_data_frame=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m <- flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m flush.poll=Ready\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m read_preface;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m -- flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m -> read_preface;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m <- read_preface;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m -- read_preface;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=65535; old=0; new=65535\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=65535; old=0; new=65535\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::new; flow=FlowControl { window_size: Window(65535), available: Window(65535) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m Connection; peer=Server\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m connection established!\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m set_target_connection_window; target=1048576; available=65535, reserved=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m <- server_handshake;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m -- server_handshake;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m -- server_handshake;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=45\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=45\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 45B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Settings\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Settings { flags: (0x0), enable_push: 0, max_concurrent_streams: 0, initial_window_size: 4194304, max_frame_size: 4194304, max_header_list_size: 16384 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv SETTINGS frame=Settings { flags: (0x0), enable_push: 0, max_concurrent_streams: 0, initial_window_size: 4194304, max_frame_size: 4194304, max_header_list_size: 16384 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Settings { flags: (0x1: ACK) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Settings { flags: (0x1: ACK) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::settings\u001b[0m\u001b[38;5;8m]\u001b[0m encoding SETTINGS; len=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m encoded settings rem=9\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::settings\u001b[0m\u001b[38;5;8m]\u001b[0m ACK sent; applying settings\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(0), size_increment: 4128769 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(0), size_increment: 4128769 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=4128769; old=65535; new=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=4128769\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=9\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=9\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 9B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Settings\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Settings { flags: (0x1: ACK) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv SETTINGS frame=Settings { flags: (0x1: ACK) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::proto::settings\u001b[0m\u001b[38;5;8m]\u001b[0m received settings ACK; applying Settings { flags: (0x0), initial_window_size: 1048576, max_frame_size: 16384, max_header_list_size: 16777216 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m update_initial_window_size; new=1048576; old=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=270\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=270\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 270B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Headers\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::headers\u001b[0m\u001b[38;5;8m]\u001b[0m loading headers; flags=(0x4: END_HEADERS)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m decode\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=261 kind=LiteralWithIndexing\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=198 kind=LiteralWithIndexing\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=170 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=169 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=168 kind=LiteralWithIndexing\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=137 kind=LiteralWithIndexing\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=124 kind=LiteralWithIndexing\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=78 kind=LiteralWithIndexing\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=61 kind=LiteralWithIndexing\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Headers { stream_id: StreamId(1), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv HEADERS frame=Headers { stream_id: StreamId(1), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=1048576; old=0; new=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=4194304; old=0; new=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m recv_headers; stream=StreamId(1); state=State { inner: Idle }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m opening stream; init_window=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(1); state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(1), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(1), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m recv_stream_window_update; stream.id=StreamId(1) stream.state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } } inc=5 flow=FlowControl { window_size: Window(4194304), available: Window(0) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=5; old=4194304; new=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(1)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=0 additional=0 buffered=0 window=4194309 conn=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=14\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=14\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 14B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Data\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Data { stream_id: StreamId(1), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv DATA frame=Data { stream_id: StreamId(1), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m recv_data; size=5; connection=65535; stream=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=65535; available=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m recv_close: Open => HalfClosedRemote(AwaitingHeaders)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=1048576; available=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(1); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(0), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(0), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=5; old=4194304; new=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=WindowUpdate { stream_id: StreamId(0), size_increment: 983041 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=WindowUpdate { stream_id: StreamId(0), size_increment: 983041 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::window_update\u001b[0m\u001b[38;5;8m]\u001b[0m encoding WINDOW_UPDATE; id=StreamId(0)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m encoded window_update rem=22\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=983041; old=65530; new=1048571\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m queued_data_frame=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m next_incoming; id=StreamId(1), state=State { inner: HalfClosedRemote(AwaitingHeaders) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m received incoming\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m incoming request\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_capacity; size=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_connection_capacity; size=5, connection in_flight_data=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(1), state: State { inner: HalfClosedRemote(AwaitingHeaders) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: false, send_flow: FlowControl { window_size: Window(4194309), available: Window(0) }, requested_send_capacity: 0, buffered_send_data: 0, send_task: None, pending_send: Deque { indices: None }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: false, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(1); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_headers; frame=Headers { stream_id: StreamId(1), flags: (0x4: END_HEADERS) }; init_window=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(1)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(1)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(1); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(1) requested=1 effective=1 curr=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(1)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=1 additional=1 buffered=0 window=4194309 conn=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=1; buffered=0; id=StreamId(1); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=1 requested=1 buffered=0 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2\u001b[0m\u001b[38;5;8m]\u001b[0m send body chunk: 12 bytes, eos=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=12 requested=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m buffered=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(1)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=12 additional=11 buffered=12 window=4194309 conn=4194308\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=11\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=12; buffered=12; id=StreamId(1); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=12 requested=12 buffered=12 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=12 buffered=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(1)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(1)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(1); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=12; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(1) requested=1 effective=13 curr=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(1)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=13 additional=1 buffered=12 window=4194309 conn=4194297\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=13; buffered=12; id=StreamId(1); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=13 requested=13 buffered=12 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(1) requested=0 effective=12 curr=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m send_close: HalfClosedRemote => Closed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_trailers -- queuing; frame=Headers { stream_id: StreamId(1), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(1)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(1)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(1) requested=0 effective=12 curr=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(1); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=12; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(1), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(12) }, requested_send_capacity: 12, buffered_send_data: 12, send_task: Some(Waker { data: 0x7f81b000a380, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 0, tail: 2 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(1); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=12; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(1), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 1, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(12) }, requested_send_capacity: 12, buffered_send_data: 12, send_task: Some(Waker { data: 0x7f81b000a380, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 0, tail: 2 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(1); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=12; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(1) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(1), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(1); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=12; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(1), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(1), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(1), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(1) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m data frame sz=12 eos=false window=12 available=12 requested=12 buffered=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m sending data frame len=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=12; window=4194309; available=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   sent stream data; available=0; buffered=0; id=StreamId(1); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=12; window=4194309; available=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Data { stream_id: StreamId(1) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(1); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Data { stream_id: StreamId(1) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Data { stream_id: StreamId(1) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Data { stream_id: StreamId(1) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reclaimed frame=Data { stream_id: StreamId(1) } sz=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(1) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(1), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(1); state=State { inner: Closed(EndStream) }; is_closed=true; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m dec_num_streams; stream=StreamId(1)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(1), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(1), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(1), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m queued_data_frame=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 17B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Ping\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Ping { ack: false, payload: [34, 195, 21, 241, 55, 223, 93, 214] }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv PING frame=Ping { ack: false, payload: [34, 195, 21, 241, 55, 223, 93, 214] }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "I0218 12:32:43.613791 139713981884224 server_ingester.py:189] Got valid response from data server\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Ping { ack: true, payload: [34, 195, 21, 241, 55, 223, 93, 214] }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Ping { ack: true, payload: [34, 195, 21, 241, 55, 223, 93, 214] }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::ping\u001b[0m\u001b[38;5;8m]\u001b[0m encoding PING; ack=true len=8\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m encoded ping rem=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m queued_data_frame=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:43Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.18.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "I0218 12:32:46.070700 139699767203392 _internal.py:97] 127.0.0.1 - - [18/Feb/2025 12:32:46] \"GET / HTTP/1.1\" 200 -\n",
      "I0218 12:32:46.400951 139699767203392 _internal.py:97] 127.0.0.1 - - [18/Feb/2025 12:32:46] \"GET /font-roboto/d-6IYplOFocCacKzxwXSOJBw1xU1rKptJj_0jans920.woff2 HTTP/1.1\" 200 -\n",
      "I0218 12:32:46.401627 139699758810688 _internal.py:97] 127.0.0.1 - - [18/Feb/2025 12:32:46] \"GET /font-roboto/vPcynSL0qHq_6dX7lKVByXYhjbSpvc47ee6xR_80Hnw.woff2 HTTP/1.1\" 200 -\n",
      "I0218 12:32:46.403086 139699750417984 _internal.py:97] 127.0.0.1 - - [18/Feb/2025 12:32:46] \"GET /font-roboto/oMMgfZMQthOryQo9n22dcuvvDin1pK8aKteLpeZ5c0A.woff2 HTTP/1.1\" 200 -\n",
      "I0218 12:32:46.408042 139699742025280 _internal.py:97] 127.0.0.1 - - [18/Feb/2025 12:32:46] \"GET /font-roboto/RxZJdnzeo3R5zSexge8UUZBw1xU1rKptJj_0jans920.woff2 HTTP/1.1\" 200 -\n",
      "I0218 12:32:46.779575 139699742025280 _internal.py:97] 127.0.0.1 - - [18/Feb/2025 12:32:46] \"GET /icon_bundle.svg HTTP/1.1\" 200 -\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 17B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Headers\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::headers\u001b[0m\u001b[38;5;8m]\u001b[0m loading headers; flags=(0x4: END_HEADERS)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m decode\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=8 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=7 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=6 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=5 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=4 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=3 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=2 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=1 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Headers { stream_id: StreamId(3), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv HEADERS frame=Headers { stream_id: StreamId(3), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=1048576; old=0; new=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=4194304; old=0; new=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m recv_headers; stream=StreamId(3); state=State { inner: Idle }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m opening stream; init_window=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(3); state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(3), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(3), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m recv_stream_window_update; stream.id=StreamId(3) stream.state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } } inc=5 flow=FlowControl { window_size: Window(4194304), available: Window(0) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=5; old=4194304; new=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(3)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=0 additional=0 buffered=0 window=4194309 conn=4194297\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=14\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=14\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 14B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Data\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Data { stream_id: StreamId(3), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv DATA frame=Data { stream_id: StreamId(3), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m recv_data; size=5; connection=1048571; stream=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=1048571; available=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m recv_close: Open => HalfClosedRemote(AwaitingHeaders)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=1048576; available=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(3); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(0), size_increment: 12 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(0), size_increment: 12 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=12; old=4194297; new=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m next_incoming; id=StreamId(3), state=State { inner: HalfClosedRemote(AwaitingHeaders) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m received incoming\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m incoming request\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_capacity; size=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_connection_capacity; size=5, connection in_flight_data=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(3), state: State { inner: HalfClosedRemote(AwaitingHeaders) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: false, send_flow: FlowControl { window_size: Window(4194309), available: Window(0) }, requested_send_capacity: 0, buffered_send_data: 0, send_task: None, pending_send: Deque { indices: None }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: false, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(3); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_headers; frame=Headers { stream_id: StreamId(3), flags: (0x4: END_HEADERS) }; init_window=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(3)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(3)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(3); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(3) requested=1 effective=1 curr=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(3)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=1 additional=1 buffered=0 window=4194309 conn=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=1; buffered=0; id=StreamId(3); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=1 requested=1 buffered=0 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2\u001b[0m\u001b[38;5;8m]\u001b[0m send body chunk: 12 bytes, eos=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=12 requested=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m buffered=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(3)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=12 additional=11 buffered=12 window=4194309 conn=4194308\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=11\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=12; buffered=12; id=StreamId(3); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=12 requested=12 buffered=12 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=12 buffered=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(3)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(3)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(3); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=12; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(3) requested=1 effective=13 curr=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(3)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=13 additional=1 buffered=12 window=4194309 conn=4194297\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=13; buffered=12; id=StreamId(3); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=13 requested=13 buffered=12 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(3) requested=0 effective=12 curr=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m send_close: HalfClosedRemote => Closed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_trailers -- queuing; frame=Headers { stream_id: StreamId(3), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(3)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(3)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(3) requested=0 effective=12 curr=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(3); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=12; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(3), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(12) }, requested_send_capacity: 12, buffered_send_data: 12, send_task: Some(Waker { data: 0x7f8228002380, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 2, tail: 0 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(3); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=12; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(3), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 1, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(12) }, requested_send_capacity: 12, buffered_send_data: 12, send_task: Some(Waker { data: 0x7f8228002380, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 2, tail: 0 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(3); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=12; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(3) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(3), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(3); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=12; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(3), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(3), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(3), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(3) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m data frame sz=12 eos=false window=12 available=12 requested=12 buffered=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m sending data frame len=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=12; window=4194309; available=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   sent stream data; available=0; buffered=0; id=StreamId(3); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=12; window=4194309; available=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Data { stream_id: StreamId(3) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(3); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Data { stream_id: StreamId(3) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Data { stream_id: StreamId(3) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Data { stream_id: StreamId(3) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reclaimed frame=Data { stream_id: StreamId(3) } sz=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(3) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(3), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(3); state=State { inner: Closed(EndStream) }; is_closed=true; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m dec_num_streams; stream=StreamId(3)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(3), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(3), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(3), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m queued_data_frame=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=77\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=77\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 77B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Headers\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::headers\u001b[0m\u001b[38;5;8m]\u001b[0m loading headers; flags=(0x4: END_HEADERS)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m decode\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=68 kind=LiteralWithIndexing\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=7 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=6 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=5 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=4 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=3 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=2 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=1 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Headers { stream_id: StreamId(5), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv HEADERS frame=Headers { stream_id: StreamId(5), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=1048576; old=0; new=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=4194304; old=0; new=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m recv_headers; stream=StreamId(5); state=State { inner: Idle }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m opening stream; init_window=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(5); state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(5), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(5), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m recv_stream_window_update; stream.id=StreamId(5) stream.state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } } inc=5 flow=FlowControl { window_size: Window(4194304), available: Window(0) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=5; old=4194304; new=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(5)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=0 additional=0 buffered=0 window=4194309 conn=4194297\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=14\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=14\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 14B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Data\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "I0218 12:32:46.787819 139699750417984 _internal.py:97] 127.0.0.1 - - [18/Feb/2025 12:32:46] \"GET /data/environment HTTP/1.1\" 200 -\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Data { stream_id: StreamId(5), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv DATA frame=Data { stream_id: StreamId(5), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m recv_data; size=5; connection=1048566; stream=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=1048566; available=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m recv_close: Open => HalfClosedRemote(AwaitingHeaders)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=1048576; available=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(5); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(0), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(0), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=5; old=4194297; new=4194302\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m next_incoming; id=StreamId(5), state=State { inner: HalfClosedRemote(AwaitingHeaders) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m received incoming\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m incoming request\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_capacity; size=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_connection_capacity; size=5, connection in_flight_data=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(5), state: State { inner: HalfClosedRemote(AwaitingHeaders) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: false, send_flow: FlowControl { window_size: Window(4194309), available: Window(0) }, requested_send_capacity: 0, buffered_send_data: 0, send_task: None, pending_send: Deque { indices: None }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: false, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(5); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_headers; frame=Headers { stream_id: StreamId(5), flags: (0x4: END_HEADERS) }; init_window=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(5)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(5)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(5); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(5) requested=1 effective=1 curr=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(5)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=1 additional=1 buffered=0 window=4194309 conn=4194302\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=1; buffered=0; id=StreamId(5); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=1 requested=1 buffered=0 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2\u001b[0m\u001b[38;5;8m]\u001b[0m send body chunk: 5 bytes, eos=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5 requested=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(5)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=5 additional=4 buffered=5 window=4194309 conn=4194301\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=4\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=5; buffered=5; id=StreamId(5); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=5 requested=5 buffered=5 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=5 buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(5)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(5)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(5); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(5) requested=1 effective=6 curr=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(5)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=6 additional=1 buffered=5 window=4194309 conn=4194297\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "I0218 12:32:46.790254 139699733632576 timing.py:122] Thread-10 (process_request_thread)[7f0e60ff9640] ENTER GrpcDataProvider.list_tensors\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=6; buffered=5; id=StreamId(5); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=6 requested=6 buffered=5 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(5) requested=0 effective=5 curr=6\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m send_close: HalfClosedRemote => Closed\n",
      "I0218 12:32:46.791267 139699733632576 timing.py:122] Thread-10 (process_request_thread)[7f0e60ff9640]   ENTER build request\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_trailers -- queuing; frame=Headers { stream_id: StreamId(5), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(5)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(5)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(5) requested=0 effective=5 curr=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(5); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(5), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(5) }, requested_send_capacity: 5, buffered_send_data: 5, send_task: Some(Waker { data: 0x7f8228002380, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 0, tail: 2 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(5); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "I0218 12:32:46.791315 139699733632576 timing.py:122] Thread-10 (process_request_thread)[7f0e60ff9640]   LEAVE build request - 0.000051s elapsed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(5), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 1, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(5) }, requested_send_capacity: 5, buffered_send_data: 5, send_task: Some(Waker { data: 0x7f8228002380, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 0, tail: 2 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(5); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "I0218 12:32:46.791349 139699733632576 timing.py:122] Thread-10 (process_request_thread)[7f0e60ff9640]   ENTER _stub.ListTensors\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(5) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(5), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(5); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(5), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(5), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(5), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(5) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m data frame sz=5 eos=false window=5 available=5 requested=5 buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m sending data frame len=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=4194309; available=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   sent stream data; available=0; buffered=0; id=StreamId(5); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=4194302; available=4194302\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Data { stream_id: StreamId(5) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(5); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Data { stream_id: StreamId(5) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Data { stream_id: StreamId(5) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Data { stream_id: StreamId(5) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reclaimed frame=Data { stream_id: StreamId(5) } sz=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(5) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(5), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(5); state=State { inner: Closed(EndStream) }; is_closed=true; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m dec_num_streams; stream=StreamId(5)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(5), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(5), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(5), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m queued_data_frame=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=74\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=74\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 74B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Headers\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::headers\u001b[0m\u001b[38;5;8m]\u001b[0m loading headers; flags=(0x4: END_HEADERS)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m decode\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=65 kind=LiteralWithIndexing\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=7 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=6 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=5 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=4 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=3 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=2 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=1 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Headers { stream_id: StreamId(7), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "I0218 12:32:46.793145 139699758810688 application.py:438] Plugin listing: is_active() for timeseries took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv HEADERS frame=Headers { stream_id: StreamId(7), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=1048576; old=0; new=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=4194304; old=0; new=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m recv_headers; stream=StreamId(7); state=State { inner: Idle }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m opening stream; init_window=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(7); state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "I0218 12:32:46.793232 139699758810688 application.py:438] Plugin listing: is_active() for scalars took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "I0218 12:32:46.793269 139699758810688 application.py:438] Plugin listing: is_active() for custom_scalars took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(7), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "I0218 12:32:46.793298 139699758810688 application.py:438] Plugin listing: is_active() for images took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(7), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m recv_stream_window_update; stream.id=StreamId(7) stream.state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } } inc=5 flow=FlowControl { window_size: Window(4194304), available: Window(0) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=5; old=4194304; new=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(7)\n",
      "I0218 12:32:46.793323 139699758810688 application.py:438] Plugin listing: is_active() for audio took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=0 additional=0 buffered=0 window=4194309 conn=4194297\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- recv_stream_window_update;\n",
      "I0218 12:32:46.793347 139699758810688 application.py:438] Plugin listing: is_active() for debugger-v2 took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "I0218 12:32:46.793374 139699758810688 application.py:438] Plugin listing: is_active() for graphs took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=35\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=35\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 35B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Data\n",
      "I0218 12:32:46.793399 139699758810688 application.py:438] Plugin listing: is_active() for distributions took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Data { stream_id: StreamId(7), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv DATA frame=Data { stream_id: StreamId(7), flags: (0x1: END_STREAM) }\n",
      "I0218 12:32:46.793420 139699758810688 application.py:438] Plugin listing: is_active() for histograms took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m recv_data; size=26; connection=1048561; stream=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=26; window=1048561; available=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m recv_close: Open => HalfClosedRemote(AwaitingHeaders)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=26; window=1048576; available=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(7); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "I0218 12:32:46.793441 139699758810688 application.py:438] Plugin listing: is_active() for text took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "I0218 12:32:46.793462 139699758810688 application.py:438] Plugin listing: is_active() for pr_curves took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "I0218 12:32:46.793490 139699758810688 application.py:438] Plugin listing: is_active() for profile_redirect took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(0), size_increment: 12 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "I0218 12:32:46.794883 139699758810688 application.py:438] Plugin listing: is_active() for hparams took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(0), size_increment: 12 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=12; old=4194297; new=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=12\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "I0218 12:32:46.794910 139699758810688 application.py:438] Plugin listing: is_active() for mesh took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=77\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=77\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "I0218 12:32:46.794935 139699758810688 application.py:438] Plugin listing: is_active() for wit_redirect took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 77B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Headers\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::headers\u001b[0m\u001b[38;5;8m]\u001b[0m loading headers; flags=(0x4: END_HEADERS)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m decode\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=68 kind=LiteralWithIndexing\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=7 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=6 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=5 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=4 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=3 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=2 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=1 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Headers { stream_id: StreamId(9), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv HEADERS frame=Headers { stream_id: StreamId(9), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=1048576; old=0; new=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=4194304; old=0; new=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m recv_headers; stream=StreamId(9); state=State { inner: Idle }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m opening stream; init_window=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> existing entries\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(9); state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=2; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(9), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "I0218 12:32:46.795125 139699758810688 application.py:438] Plugin listing: is_active() for projector took 0.000 seconds\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(9), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m recv_stream_window_update; stream.id=StreamId(9) stream.state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } } inc=5 flow=FlowControl { window_size: Window(4194304), available: Window(0) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=5; old=4194304; new=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(9)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=0 additional=0 buffered=0 window=4194309 conn=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=46\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=46\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 46B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Data\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Data { stream_id: StreamId(9), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv DATA frame=Data { stream_id: StreamId(9), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m recv_data; size=37; connection=1048535; stream=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=37; window=1048535; available=1048550\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m recv_close: Open => HalfClosedRemote(AwaitingHeaders)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=37; window=1048576; available=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(9); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=2; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(0), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(0), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=5; old=4194309; new=4194314\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 17B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Headers\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::headers\u001b[0m\u001b[38;5;8m]\u001b[0m loading headers; flags=(0x4: END_HEADERS)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m decode\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=8 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=7 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=6 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=5 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=4 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=3 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=2 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=1 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Headers { stream_id: StreamId(11), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv HEADERS frame=Headers { stream_id: StreamId(11), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=1048576; old=0; new=1048576\n",
      "I0218 12:32:46.795539 139699758810688 _internal.py:97] 127.0.0.1 - - [18/Feb/2025 12:32:46] \"GET /data/plugins_listing HTTP/1.1\" 200 -\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=4194304; old=0; new=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m recv_headers; stream=StreamId(11); state=State { inner: Idle }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m opening stream; init_window=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> existing entries\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(11); state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=3; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(11), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(11), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m recv_stream_window_update; stream.id=StreamId(11) stream.state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } } inc=5 flow=FlowControl { window_size: Window(4194304), available: Window(0) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=5; old=4194304; new=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(11)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=0 additional=0 buffered=0 window=4194309 conn=4194314\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=14\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=14\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 14B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Data\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Data { stream_id: StreamId(11), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv DATA frame=Data { stream_id: StreamId(11), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m recv_data; size=5; connection=1048498; stream=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=1048498; available=1048513\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m recv_close: Open => HalfClosedRemote(AwaitingHeaders)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=1048576; available=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(11); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=3; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(0), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(0), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=5; old=4194314; new=4194319\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m next_incoming; id=StreamId(7), state=State { inner: HalfClosedRemote(AwaitingHeaders) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m received incoming\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m incoming request\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m next_incoming; id=StreamId(9), state=State { inner: HalfClosedRemote(AwaitingHeaders) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m received incoming\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m incoming request\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_capacity; size=26\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_connection_capacity; size=26, connection in_flight_data=68\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(7), state: State { inner: HalfClosedRemote(AwaitingHeaders) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: false, send_flow: FlowControl { window_size: Window(4194309), available: Window(0) }, requested_send_capacity: 0, buffered_send_data: 0, send_task: None, pending_send: Deque { indices: None }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: false, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048550), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(7); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=3; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_headers; frame=Headers { stream_id: StreamId(7), flags: (0x4: END_HEADERS) }; init_window=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(7)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(7)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(7); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=3; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(7) requested=1 effective=1 curr=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(7)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=1 additional=1 buffered=0 window=4194309 conn=4194319\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=1; buffered=0; id=StreamId(7); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=1 requested=1 buffered=0 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2\u001b[0m\u001b[38;5;8m]\u001b[0m send body chunk: 5 bytes, eos=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m next_incoming; id=StreamId(11), state=State { inner: HalfClosedRemote(AwaitingHeaders) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m received incoming\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m incoming request\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5 requested=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(7)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=5 additional=4 buffered=5 window=4194309 conn=4194318\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=4\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=5; buffered=5; id=StreamId(7); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=5 requested=5 buffered=5 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=5 buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(7)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(7)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(7); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=3; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(7) requested=1 effective=6 curr=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(7)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=6 additional=1 buffered=5 window=4194309 conn=4194314\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=6; buffered=5; id=StreamId(7); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=6 requested=6 buffered=5 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(7) requested=0 effective=5 curr=6\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m send_close: HalfClosedRemote => Closed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_trailers -- queuing; frame=Headers { stream_id: StreamId(7), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(7)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(7)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(7) requested=0 effective=5 curr=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(7); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=3; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(7), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(5) }, requested_send_capacity: 5, buffered_send_data: 5, send_task: Some(Waker { data: 0x7f8228002380, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 2, tail: 0 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048550), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(7); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=3; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(7), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 1, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(5) }, requested_send_capacity: 5, buffered_send_data: 5, send_task: Some(Waker { data: 0x7f8228002380, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 2, tail: 0 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048550), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(7); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=3; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_capacity; size=37\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_connection_capacity; size=37, connection in_flight_data=42\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(9), state: State { inner: HalfClosedRemote(AwaitingHeaders) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: false, send_flow: FlowControl { window_size: Window(4194309), available: Window(0) }, requested_send_capacity: 0, buffered_send_data: 0, send_task: None, pending_send: Deque { indices: None }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: false, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048539), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(9); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=3; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_headers; frame=Headers { stream_id: StreamId(9), flags: (0x4: END_HEADERS) }; init_window=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(9)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(9)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> existing entries\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 17B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Headers\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::headers\u001b[0m\u001b[38;5;8m]\u001b[0m loading headers; flags=(0x4: END_HEADERS)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m decode\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=8 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=7 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=6 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=5 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(9); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=3; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(9) requested=1 effective=1 curr=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=4 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(9)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=3 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=2 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=1 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=1 additional=1 buffered=0 window=4194309 conn=4194314\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=1; buffered=0; id=StreamId(9); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Headers { stream_id: StreamId(13), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv HEADERS frame=Headers { stream_id: StreamId(13), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=1 requested=1 buffered=0 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2\u001b[0m\u001b[38;5;8m]\u001b[0m send body chunk: 5 bytes, eos=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=1048576; old=0; new=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=4194304; old=0; new=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m recv_headers; stream=StreamId(13); state=State { inner: Idle }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m opening stream; init_window=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(13); state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=4; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5 requested=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(9)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=5 additional=4 buffered=5 window=4194309 conn=4194313\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=4\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=5; buffered=5; id=StreamId(9); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=5 requested=5 buffered=5 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=5 buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(9)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(9)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(9); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=4; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(9) requested=1 effective=6 curr=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(9)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=6 additional=1 buffered=5 window=4194309 conn=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=6; buffered=5; id=StreamId(9); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=6 requested=6 buffered=5 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(9) requested=0 effective=5 curr=6\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m send_close: HalfClosedRemote => Closed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_trailers -- queuing; frame=Headers { stream_id: StreamId(9), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(9)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(9)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(9) requested=0 effective=5 curr=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(9); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=4; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(9), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(5) }, requested_send_capacity: 5, buffered_send_data: 5, send_task: Some(Waker { data: 0x7f8228002430, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 3, tail: 5 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048539), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(9); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=4; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(13), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(9), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 1, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(5) }, requested_send_capacity: 5, buffered_send_data: 5, send_task: Some(Waker { data: 0x7f8228002430, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 3, tail: 5 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048539), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(9); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=4; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(13), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m recv_stream_window_update; stream.id=StreamId(13) stream.state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } } inc=5 flow=FlowControl { window_size: Window(4194304), available: Window(0) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=5; old=4194304; new=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(13)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=0 additional=0 buffered=0 window=4194309 conn=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=14\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=14\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 14B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Data\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Data { stream_id: StreamId(13), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv DATA frame=Data { stream_id: StreamId(13), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m recv_data; size=5; connection=1048493; stream=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=1048493; available=1048571\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m recv_close: Open => HalfClosedRemote(AwaitingHeaders)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=1048576; available=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(13); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=4; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(0), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(0), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=5; old=4194319; new=4194324\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(7) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(7), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> existing entries\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(7); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=4; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(7), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(7), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(7), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(9) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(9), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> existing entries\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(9); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=4; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(9), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(9), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(9), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(7) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m data frame sz=5 eos=false window=5 available=5 requested=5 buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m sending data frame len=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=4194309; available=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   sent stream data; available=0; buffered=0; id=StreamId(7); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=4194324; available=4194319\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Data { stream_id: StreamId(7) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> existing entries\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(7); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=4; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Data { stream_id: StreamId(7) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Data { stream_id: StreamId(7) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Data { stream_id: StreamId(7) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reclaimed frame=Data { stream_id: StreamId(7) } sz=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(9) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m data frame sz=5 eos=false window=5 available=5 requested=5 buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m sending data frame len=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=4194309; available=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   sent stream data; available=0; buffered=0; id=StreamId(9); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=4194319; available=4194319\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Data { stream_id: StreamId(9) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> existing entries\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(9); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=4; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Data { stream_id: StreamId(9) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Data { stream_id: StreamId(9) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Data { stream_id: StreamId(9) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reclaimed frame=Data { stream_id: StreamId(9) } sz=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(7) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(7), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(7); state=State { inner: Closed(EndStream) }; is_closed=true; pending_send_empty=true; buffered_send_data=0; num_recv=4; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m dec_num_streams; stream=StreamId(7)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(7), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(7), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(7), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(9) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(9), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(9); state=State { inner: Closed(EndStream) }; is_closed=true; pending_send_empty=true; buffered_send_data=0; num_recv=3; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m dec_num_streams; stream=StreamId(9)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(9), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(9), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(9), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m queued_data_frame=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m next_incoming; id=StreamId(13), state=State { inner: HalfClosedRemote(AwaitingHeaders) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m received incoming\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m incoming request\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_capacity; size=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_connection_capacity; size=5, connection in_flight_data=10\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(11), state: State { inner: HalfClosedRemote(AwaitingHeaders) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: false, send_flow: FlowControl { window_size: Window(4194309), available: Window(0) }, requested_send_capacity: 0, buffered_send_data: 0, send_task: None, pending_send: Deque { indices: None }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: false, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(11); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=2; num_send=0\n",
      "I0218 12:32:46.805826 139699767203392 _internal.py:97] 127.0.0.1 - - [18/Feb/2025 12:32:46] \"GET /experiment/defaultExperimentId/data/runs HTTP/1.1\" 200 -\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_headers; frame=Headers { stream_id: StreamId(11), flags: (0x4: END_HEADERS) }; init_window=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(11)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(11)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(11); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=2; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(11) requested=1 effective=1 curr=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(11)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=1 additional=1 buffered=0 window=4194309 conn=4194314\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=1; buffered=0; id=StreamId(11); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=1 requested=1 buffered=0 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2\u001b[0m\u001b[38;5;8m]\u001b[0m send body chunk: 5 bytes, eos=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5 requested=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(11)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=5 additional=4 buffered=5 window=4194309 conn=4194313\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=4\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=5; buffered=5; id=StreamId(11); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=5 requested=5 buffered=5 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=5 buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(11)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(11)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "I0218 12:32:46.805912 139699733632576 timing.py:122] Thread-10 (process_request_thread)[7f0e60ff9640]   LEAVE _stub.ListTensors - 0.014560s elapsed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(11); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=2; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(11) requested=1 effective=6 curr=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(11)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=6 additional=1 buffered=5 window=4194309 conn=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=6; buffered=5; id=StreamId(11); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=6 requested=6 buffered=5 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(11) requested=0 effective=5 curr=6\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "I0218 12:32:46.807068 139699733632576 timing.py:122] Thread-10 (process_request_thread)[7f0e60ff9640]   ENTER build result\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m send_close: HalfClosedRemote => Closed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_trailers -- queuing; frame=Headers { stream_id: StreamId(11), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(11)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(11)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(11) requested=0 effective=5 curr=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(11); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=2; num_send=0\n",
      "I0218 12:32:46.807110 139699733632576 timing.py:122] Thread-10 (process_request_thread)[7f0e60ff9640]   LEAVE build result - 0.000044s elapsed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(11), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(5) }, requested_send_capacity: 5, buffered_send_data: 5, send_task: Some(Waker { data: 0x7f8228002160, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 5, tail: 4 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(11); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=2; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(11), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 1, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(5) }, requested_send_capacity: 5, buffered_send_data: 5, send_task: Some(Waker { data: 0x7f8228002160, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 5, tail: 4 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(11); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=2; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "I0218 12:32:46.807145 139699733632576 timing.py:122] Thread-10 (process_request_thread)[7f0e60ff9640] LEAVE GrpcDataProvider.list_tensors - 0.016904s elapsed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(11) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(11), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(11); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=2; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "I0218 12:32:46.807974 139699733632576 _internal.py:97] 127.0.0.1 - - [18/Feb/2025 12:32:46] \"POST /experiment/defaultExperimentId/data/plugin/hparams/experiment HTTP/1.1\" 200 -\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(11), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(11), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(11), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(11) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m data frame sz=5 eos=false window=5 available=5 requested=5 buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m sending data frame len=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=4194309; available=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   sent stream data; available=0; buffered=0; id=StreamId(11); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=4194314; available=4194314\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Data { stream_id: StreamId(11) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(11); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=2; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Data { stream_id: StreamId(11) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Data { stream_id: StreamId(11) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Data { stream_id: StreamId(11) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reclaimed frame=Data { stream_id: StreamId(11) } sz=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(11) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(11), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(11); state=State { inner: Closed(EndStream) }; is_closed=true; pending_send_empty=true; buffered_send_data=0; num_recv=2; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m dec_num_streams; stream=StreamId(11)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(11), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(11), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(11), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m queued_data_frame=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_capacity; size=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_connection_capacity; size=5, connection in_flight_data=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(13), state: State { inner: HalfClosedRemote(AwaitingHeaders) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: false, send_flow: FlowControl { window_size: Window(4194309), available: Window(0) }, requested_send_capacity: 0, buffered_send_data: 0, send_task: None, pending_send: Deque { indices: None }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: false, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(13); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_headers; frame=Headers { stream_id: StreamId(13), flags: (0x4: END_HEADERS) }; init_window=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(13)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(13)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(13); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(13) requested=1 effective=1 curr=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(13)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=1 additional=1 buffered=0 window=4194309 conn=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=1; buffered=0; id=StreamId(13); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=1 requested=1 buffered=0 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2\u001b[0m\u001b[38;5;8m]\u001b[0m send body chunk: 5 bytes, eos=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5 requested=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(13)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=5 additional=4 buffered=5 window=4194309 conn=4194308\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=4\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=5; buffered=5; id=StreamId(13); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=5 requested=5 buffered=5 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=5 buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(13)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(13)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(13); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(13) requested=1 effective=6 curr=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(13)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=6 additional=1 buffered=5 window=4194309 conn=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=6; buffered=5; id=StreamId(13); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=6 requested=6 buffered=5 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(13) requested=0 effective=5 curr=6\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m send_close: HalfClosedRemote => Closed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_trailers -- queuing; frame=Headers { stream_id: StreamId(13), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(13)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(13)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(13) requested=0 effective=5 curr=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(13); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(13), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(5) }, requested_send_capacity: 5, buffered_send_data: 5, send_task: Some(Waker { data: 0x7f8228002430, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 4, tail: 5 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(13); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(13), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 1, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(5) }, requested_send_capacity: 5, buffered_send_data: 5, send_task: Some(Waker { data: 0x7f8228002430, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 4, tail: 5 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048571), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(13); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(13) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(13), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(13); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(13), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(13), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(13), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(13) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m data frame sz=5 eos=false window=5 available=5 requested=5 buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m sending data frame len=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=4194309; available=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   sent stream data; available=0; buffered=0; id=StreamId(13); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=4194309; available=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Data { stream_id: StreamId(13) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(13); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Data { stream_id: StreamId(13) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Data { stream_id: StreamId(13) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Data { stream_id: StreamId(13) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reclaimed frame=Data { stream_id: StreamId(13) } sz=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(13) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(13), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(13); state=State { inner: Closed(EndStream) }; is_closed=true; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m dec_num_streams; stream=StreamId(13)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(13), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(13), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(13), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m queued_data_frame=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "I0218 12:32:46.846188 139699641378368 _internal.py:97] 127.0.0.1 - - [18/Feb/2025 12:32:46] \"GET /data/runs HTTP/1.1\" 200 -\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 17B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Ping\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Ping { ack: false, payload: [238, 131, 127, 206, 227, 80, 191, 62] }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv PING frame=Ping { ack: false, payload: [238, 131, 127, 206, 227, 80, 191, 62] }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Ping { ack: true, payload: [238, 131, 127, 206, 227, 80, 191, 62] }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Ping { ack: true, payload: [238, 131, 127, 206, 227, 80, 191, 62] }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::ping\u001b[0m\u001b[38;5;8m]\u001b[0m encoding PING; ack=true len=8\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m encoded ping rem=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m queued_data_frame=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:46Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "I0218 12:32:47.118338 139699641378368 timing.py:122] Thread-12 (process_request_thread)[7f0e5b7fe640] ENTER GrpcDataProvider.list_tensors\n",
      "I0218 12:32:47.118437 139699641378368 timing.py:122] Thread-12 (process_request_thread)[7f0e5b7fe640]   ENTER build request\n",
      "I0218 12:32:47.118475 139699641378368 timing.py:122] Thread-12 (process_request_thread)[7f0e5b7fe640]   LEAVE build request - 0.000041s elapsed\n",
      "I0218 12:32:47.118509 139699641378368 timing.py:122] Thread-12 (process_request_thread)[7f0e5b7fe640]   ENTER _stub.ListTensors\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 17B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Headers\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::headers\u001b[0m\u001b[38;5;8m]\u001b[0m loading headers; flags=(0x4: END_HEADERS)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m decode\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=8 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=7 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=6 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=5 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=4 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=3 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=2 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m rem=1 kind=Indexed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::decoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::decode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Headers { stream_id: StreamId(15), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv HEADERS frame=Headers { stream_id: StreamId(15), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=1048576; old=0; new=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=4194304; old=0; new=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m recv_headers; stream=StreamId(15); state=State { inner: Idle }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m opening stream; init_window=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(15); state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(15), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(15), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m recv_stream_window_update; stream.id=StreamId(15) stream.state=State { inner: Open { local: AwaitingHeaders, remote: Streaming } } inc=5 flow=FlowControl { window_size: Window(4194304), available: Window(0) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=5; old=4194304; new=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(15)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=0 additional=0 buffered=0 window=4194309 conn=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- recv_stream_window_update;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=46\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=46\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 46B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Data\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Data { stream_id: StreamId(15), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv DATA frame=Data { stream_id: StreamId(15), flags: (0x1: END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m recv_data; size=37; connection=1048488; stream=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=37; window=1048488; available=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m recv_close: Open => HalfClosedRemote(AwaitingHeaders)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=37; window=1048576; available=1048576\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(15); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=13\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 13B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=WindowUpdate\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=WindowUpdate { stream_id: StreamId(0), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv WINDOW_UPDATE frame=WindowUpdate { stream_id: StreamId(0), size_increment: 5 }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m inc_window; sz=5; old=4194304; new=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m next_incoming; id=StreamId(15), state=State { inner: HalfClosedRemote(AwaitingHeaders) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m received incoming\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2::server\u001b[0m\u001b[38;5;8m]\u001b[0m incoming request\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_capacity; size=37\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::recv\u001b[0m\u001b[38;5;8m]\u001b[0m release_connection_capacity; size=37, connection in_flight_data=37\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(15), state: State { inner: HalfClosedRemote(AwaitingHeaders) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: false, send_flow: FlowControl { window_size: Window(4194309), available: Window(0) }, requested_send_capacity: 0, buffered_send_data: 0, send_task: None, pending_send: Deque { indices: None }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: false, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048539), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(15); state=State { inner: HalfClosedRemote(AwaitingHeaders) }; is_closed=false; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_headers; frame=Headers { stream_id: StreamId(15), flags: (0x4: END_HEADERS) }; init_window=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(15)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(15)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(15); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(15) requested=1 effective=1 curr=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(15)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=1 additional=1 buffered=0 window=4194309 conn=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=1; buffered=0; id=StreamId(15); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=1 requested=1 buffered=0 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m hyper::proto::h2\u001b[0m\u001b[38;5;8m]\u001b[0m send body chunk: 5 bytes, eos=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5 requested=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(15)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=5 additional=4 buffered=5 window=4194309 conn=4194308\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=4\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=5; buffered=5; id=StreamId(15); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=5 requested=5 buffered=5 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=5 buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(15)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(15)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- send_data;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(15); state=State { inner: HalfClosedRemote(Streaming) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(15) requested=1 effective=6 curr=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_assign_capacity; stream.id=StreamId(15)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m requested=6 additional=1 buffered=5 window=4194309 conn=4194304\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assigning capacity=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   assigned capacity to stream; available=6; buffered=5; id=StreamId(15); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   notifying task\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m available=6 requested=6 buffered=5 has_unavailable=true\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_assign_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(15) requested=0 effective=5 curr=6\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m assign_connection_capacity; inc=1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- assign_connection_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::state\u001b[0m\u001b[38;5;8m]\u001b[0m send_close: HalfClosedRemote => Closed\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::send\u001b[0m\u001b[38;5;8m]\u001b[0m send_trailers -- queuing; frame=Headers { stream_id: StreamId(15), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m Prioritize::queue_frame; stream.id=StreamId(15)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_send stream.id=StreamId(15)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> already queued\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- Prioritize::queue_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reserve_capacity; stream.id=StreamId(15) requested=0 effective=5 curr=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- reserve_capacity;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(15); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(15), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 2, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(5) }, requested_send_capacity: 5, buffered_send_data: 5, send_task: Some(Waker { data: 0x7f81c4001f60, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 5, tail: 4 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048539), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(15); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::streams\u001b[0m\u001b[38;5;8m]\u001b[0m drop_stream_ref; stream=Stream { id: StreamId(15), state: State { inner: Closed(EndStream) }, is_counted: true, ref_count: 1, next_pending_send: None, is_pending_send: true, send_flow: FlowControl { window_size: Window(4194309), available: Window(5) }, requested_send_capacity: 5, buffered_send_data: 5, send_task: Some(Waker { data: 0x7f81c4001f60, vtable: 0x55d4fe3e4c48 }), pending_send: Deque { indices: Some(Indices { head: 5, tail: 4 }) }, next_pending_send_capacity: None, is_pending_send_capacity: false, send_capacity_inc: true, next_open: None, is_pending_open: false, is_pending_push: false, next_pending_accept: None, is_pending_accept: false, recv_flow: FlowControl { window_size: Window(1048539), available: Window(1048576) }, in_flight_recv_data: 0, next_window_update: None, is_pending_window_update: false, reset_at: None, next_reset_expire: None, pending_recv: Deque { indices: None }, is_recv: false, recv_task: None, pending_push_promises: Queue { indices: None, _p: PhantomData }, content_length: Omitted }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(15); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(15) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(15), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(15); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=5; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(15), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(15), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(15), flags: (0x4: END_HEADERS) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(15) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m data frame sz=5 eos=false window=5 available=5 requested=5 buffered=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m sending data frame len=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=4194309; available=5\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::stream\u001b[0m\u001b[38;5;8m]\u001b[0m   sent stream data; available=0; buffered=0; id=StreamId(15); max_buffer_size=409600 prev=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating stream flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::flow_control\u001b[0m\u001b[38;5;8m]\u001b[0m send_data; sz=5; window=4194309; available=4194309\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- updating connection flow;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Data { stream_id: StreamId(15) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m Queue::push\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::store\u001b[0m\u001b[38;5;8m]\u001b[0m  -> first entry\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(15); state=State { inner: Closed(EndStream) }; is_closed=false; pending_send_empty=false; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Data { stream_id: StreamId(15) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Data { stream_id: StreamId(15) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Data { stream_id: StreamId(15) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m reclaimed frame=Data { stream_id: StreamId(15) } sz=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m popped; stream.id=StreamId(15) stream.state=State { inner: Closed(EndStream) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m is_pending_reset=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame; frame=Headers { stream_id: StreamId(15), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m transition_after; stream=StreamId(15); state=State { inner: Closed(EndStream) }; is_closed=true; pending_send_empty=true; buffered_send_data=0; num_recv=1; num_send=0\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::counts\u001b[0m\u001b[38;5;8m]\u001b[0m dec_num_streams; stream=StreamId(15)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- popped;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m writing frame=Headers { stream_id: StreamId(15), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Headers { stream_id: StreamId(15), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Headers { stream_id: StreamId(15), flags: (0x5: END_HEADERS | END_STREAM) }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -> hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m <- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::hpack::encoder\u001b[0m\u001b[38;5;8m]\u001b[0m -- hpack::encode;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m queued_data_frame=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "I0218 12:32:47.122909 139699641378368 timing.py:122] Thread-12 (process_request_thread)[7f0e5b7fe640]   LEAVE _stub.ListTensors - 0.004398s elapsed\n",
      "I0218 12:32:47.122950 139699641378368 timing.py:122] Thread-12 (process_request_thread)[7f0e5b7fe640]   ENTER build result\n",
      "I0218 12:32:47.122981 139699641378368 timing.py:122] Thread-12 (process_request_thread)[7f0e5b7fe640]   LEAVE build result - 0.000032s elapsed\n",
      "I0218 12:32:47.123008 139699641378368 timing.py:122] Thread-12 (process_request_thread)[7f0e5b7fe640] LEAVE GrpcDataProvider.list_tensors - 0.004683s elapsed\n",
      "I0218 12:32:47.123581 139699641378368 _internal.py:97] 127.0.0.1 - - [18/Feb/2025 12:32:47] \"POST /experiment/defaultExperimentId/data/plugin/hparams/session_groups HTTP/1.1\" 200 -\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m connection.state=Open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m frame decoded from buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m read.bytes=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::decode_frame; offset=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m decoding frame from 17B\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m frame.kind=Ping\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::decode_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m received frame=Ping { ack: false, payload: [214, 128, 34, 114, 180, 224, 120, 18] }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m recv PING frame=Ping { ack: false, payload: [214, 128, 34, 114, 180, 224, 120, 18] }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -> poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::buffer; frame=Ping { ack: true, payload: [214, 128, 34, 114, 180, 224, 120, 18] }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[34mDEBUG\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m send frame=Ping { ack: true, payload: [214, 128, 34, 114, 180, 224, 120, 18] }\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::frame::ping\u001b[0m\u001b[38;5;8m]\u001b[0m encoding PING; ack=true len=8\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m encoded ping rem=17\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::buffer;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll_ready;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m poll\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m tokio_util::codec::framed_impl\u001b[0m\u001b[38;5;8m]\u001b[0m attempting to decode a frame\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_read\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedRead::poll_next;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m poll_complete\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m schedule_pending_open\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- pop_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -> FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m queued_data_frame=false\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m flushing buffer\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m <- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::codec::framed_write\u001b[0m\u001b[38;5;8m]\u001b[0m -- FramedWrite::flush;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -> try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m <- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::streams::prioritize\u001b[0m\u001b[38;5;8m]\u001b[0m -- try_reclaim_frame;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- poll;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m <- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:47Z \u001b[0m\u001b[36mTRACE\u001b[0m h2::proto::connection\u001b[0m\u001b[38;5;8m]\u001b[0m -- Connection;\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:48Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Starting load cycle\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:48Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Finished load cycle (81.399µs)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:53Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Starting load cycle\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:53Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Finished load cycle (73.578µs)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:58Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Starting load cycle\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:32:58Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Finished load cycle (82.647µs)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:33:03Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Starting load cycle\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:33:03Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Finished load cycle (75.823µs)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:33:08Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Starting load cycle\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:33:08Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Finished load cycle (73.841µs)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:33:13Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Starting load cycle\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:33:13Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Finished load cycle (74.535µs)\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:33:18Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Starting load cycle\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-02-18T12:33:18Z \u001b[0m\u001b[32mINFO \u001b[0m rustboard_core::cli\u001b[0m\u001b[38;5;8m]\u001b[0m Finished load cycle (67.577µs)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=./log --verbosity=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should always maintain our server clean by limiting the inclusion of unnecessary data and removing unused configurations, such as exposed ports. If we have forwarded a port, after completing the task over that connection, we should check whether the port remains active by inspecting the SSH connections with: \n",
    "`ps aux | grep ssh` or `lsof -i:6006`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a Torch utility to integrate C++ code into our Python script. This type of mixed programming is known as binding, which allows us to leverage C++ performance within Python.\n",
    "\n",
    "A temporary directory (tmp) will be created containing the following files:\n",
    "\n",
    "- .ninja_log: A log file generated by Ninja during the build process.\n",
    "- build.ninja: The build file that defines the rules and dependencies needed to compile and link our C++ code into a shared library (my_module.so).\n",
    "- .ninja_deps: A file that stores dependency information for Ninja.\n",
    "- main.cpp: The C++ source file that defines a simple function and uses Pybind11 macros to create a Python module.\n",
    "- main.o: The object file generated from compiling main.cpp.\n",
    "- my_module.so: The final shared library that is ready to be imported into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emitting ninja build file ./tmp/build.ninja...\n",
      "Building extension module my_module...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module my_module...\n",
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "!python hello_load_inline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build.ninja  main.cpp  main.o  my_module.so\n"
     ]
    }
   ],
   "source": [
    "!ls tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "!TORCH_CUDA_ARCH_LIST=9.0 python load_inline.py                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "square_matrix_extension = load_inline(\n",
    "    name='square_matrix_extension',  # Name of the Python extension module that will expose the C++/CUDA functions\n",
    "    cpp_sources=cpp_source,          # C++ source code defining the interface and wrapper function for the CUDA kernel\n",
    "    cuda_sources=cuda_source,        # CUDA source code implementing the actual CUDA kernel\n",
    "    functions=['square_matrix'],     # List of function symbols to be registered and exposed to Python\n",
    "    with_cuda=True, \n",
    "    extra_cuda_cflags=[\"-O2\"],\n",
    "    build_directory='./load_inline_cuda',\n",
    "    # extra_cuda_cflags=['--expt-relaxed-constexpr']\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: No great interaction with ncu -< Require to used `--target-processes` flag >- `ncu --target-processes all python load_inline.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==PROF== Connected to process 1573040 (/home/alex/miniforge3/envs/triton/bin/python3.10)\n",
      "/home/alex/miniforge3/envs/triton/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "==PROF== Profiling \"square_matrix_kernel\" - 0: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 1: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 2: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 3: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 4: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 5: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 6: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"DeviceReduceSingleTileKernel\" - 7: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"DeviceCompactInitKernel\" - 8: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"DeviceSelectSweepKernel\" - 9: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"index_elementwise_kernel\" - 10: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 11: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"unrolled_elementwise_kernel\" - 12: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"reduce_kernel\" - 13: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"reduce_kernel\" - 14: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 15: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 16: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"unrolled_elementwise_kernel\" - 17: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"unrolled_elementwise_kernel\" - 18: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 19: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 20: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"unrolled_elementwise_kernel\" - 21: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"unrolled_elementwise_kernel\" - 22: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 23: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 24: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"unrolled_elementwise_kernel\" - 25: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"unrolled_elementwise_kernel\" - 26: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 27: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 28: 0%....50%....100% - 10 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 29: 0%....50%....100% - 10 passes\n",
      "tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.]], device='cuda:0')\n",
      "==PROF== Disconnected from process 1573040\n",
      "[1573040] python3.10@127.0.0.1\n",
      "  square_matrix_kernel(const float *, float *, int, int) (1, 1, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.63\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        4,784\n",
      "    Memory Throughput                   %        10.44\n",
      "    DRAM Throughput                     %         0.03\n",
      "    Duration                      usecond         3.01\n",
      "    L1/TEX Cache Throughput             %        64.21\n",
      "    L2 Cache Throughput                 %        11.87\n",
      "    SM Active Cycles                cycle        10.90\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   256\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             256\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           16\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block            8\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         6.65\n",
      "    Achieved Active Warps Per SM           warp         4.25\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 93.35%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (6.6%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         2.40\n",
      "    Total DRAM Elapsed Cycles        cycle      316,928\n",
      "    Average L1 Active Cycles         cycle        10.90\n",
      "    Total L1 Elapsed Cycles          cycle      631,032\n",
      "    Average L2 Active Cycles         cycle     1,101.21\n",
      "    Total L2 Elapsed Cycles          cycle      409,840\n",
      "    Average SM Active Cycles         cycle        10.90\n",
      "    Total SM Elapsed Cycles          cycle      631,032\n",
      "    Average SMSP Active Cycles       cycle         6.27\n",
      "    Total SMSP Elapsed Cycles        cycle    2,524,128\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 7.244%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 33.70% above the average, while the minimum instance value is 12.73% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)4, at::native::AbsFunctor<float>, std::array<char *, (unsigned long)2>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.58\n",
      "    SM Frequency            cycle/nsecond         1.57\n",
      "    Elapsed Cycles                  cycle        4,819\n",
      "    Memory Throughput                   %        10.34\n",
      "    DRAM Throughput                     %         0.04\n",
      "    Duration                      usecond         3.07\n",
      "    L1/TEX Cache Throughput             %        67.94\n",
      "    L2 Cache Throughput                 %        11.73\n",
      "    SM Active Cycles                cycle        10.30\n",
      "    Compute (SM) Throughput             %         0.00\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           32\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.69\n",
      "    Achieved Active Warps Per SM           warp         2.36\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.31%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (3.7%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         2.80\n",
      "    Total DRAM Elapsed Cycles        cycle      317,440\n",
      "    Average L1 Active Cycles         cycle        10.30\n",
      "    Total L1 Elapsed Cycles          cycle      635,818\n",
      "    Average L2 Active Cycles         cycle     1,096.92\n",
      "    Total L2 Elapsed Cycles          cycle      413,840\n",
      "    Average SM Active Cycles         cycle        10.30\n",
      "    Total SM Elapsed Cycles          cycle      635,818\n",
      "    Average SMSP Active Cycles       cycle         7.31\n",
      "    Total SMSP Elapsed Cycles        cycle    2,543,272\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 7.626%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 35.96% above the average, while the minimum instance value is 12.12% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)4, at::native::AUnaryFunctor<float, float, bool, at::native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, (unsigned long)2>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.59\n",
      "    SM Frequency            cycle/nsecond         1.57\n",
      "    Elapsed Cycles                  cycle        4,981\n",
      "    Memory Throughput                   %        10.01\n",
      "    DRAM Throughput                     %         0.04\n",
      "    Duration                      usecond         3.17\n",
      "    L1/TEX Cache Throughput             %        65.91\n",
      "    L2 Cache Throughput                 %        11.36\n",
      "    SM Active Cycles                cycle        10.62\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           21\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.89\n",
      "    Achieved Active Warps Per SM           warp         2.49\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.11%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (3.9%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         3.60\n",
      "    Total DRAM Elapsed Cycles        cycle      328,192\n",
      "    Average L1 Active Cycles         cycle        10.62\n",
      "    Total L1 Elapsed Cycles          cycle      656,942\n",
      "    Average L2 Active Cycles         cycle     1,105.44\n",
      "    Total L2 Elapsed Cycles          cycle      427,520\n",
      "    Average SM Active Cycles         cycle        10.62\n",
      "    Total SM Elapsed Cycles          cycle      656,942\n",
      "    Average SMSP Active Cycles       cycle         6.54\n",
      "    Total SMSP Elapsed Cycles        cycle    2,627,768\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 10.75%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 51.96% above the average, while the minimum instance value is 12.34% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<float, float, bool, at::native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, (unsigned long)3>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.58\n",
      "    SM Frequency            cycle/nsecond         1.57\n",
      "    Elapsed Cycles                  cycle        4,815\n",
      "    Memory Throughput                   %        10.36\n",
      "    DRAM Throughput                     %         0.05\n",
      "    Duration                      usecond         3.07\n",
      "    L1/TEX Cache Throughput             %        64.84\n",
      "    L2 Cache Throughput                 %        11.85\n",
      "    SM Active Cycles                cycle        10.80\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              26\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           16\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.84\n",
      "    Achieved Active Warps Per SM           warp         2.46\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.16%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (3.8%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         3.60\n",
      "    Total DRAM Elapsed Cycles        cycle      317,312\n",
      "    Average L1 Active Cycles         cycle        10.80\n",
      "    Total L1 Elapsed Cycles          cycle      635,018\n",
      "    Average L2 Active Cycles         cycle     1,101.84\n",
      "    Total L2 Elapsed Cycles          cycle      413,200\n",
      "    Average SM Active Cycles         cycle        10.80\n",
      "    Total SM Elapsed Cycles          cycle      635,018\n",
      "    Average SMSP Active Cycles       cycle         7.00\n",
      "    Total SMSP Elapsed Cycles        cycle    2,540,072\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 6.089%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 28.54% above the average, while the minimum instance value is 11.87% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<bool, bool, bool, at::native::binary_internal::MulFunctor<bool>>, std::array<char *, (unsigned long)3>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.58\n",
      "    SM Frequency            cycle/nsecond         1.57\n",
      "    Elapsed Cycles                  cycle        5,519\n",
      "    Memory Throughput                   %         9.02\n",
      "    DRAM Throughput                     %         0.07\n",
      "    Duration                      usecond         3.52\n",
      "    L1/TEX Cache Throughput             %        55.00\n",
      "    L2 Cache Throughput                 %        10.28\n",
      "    SM Active Cycles                cycle        12.73\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              30\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           16\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         4.18\n",
      "    Achieved Active Warps Per SM           warp         2.68\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 95.82%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (4.2%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         6.60\n",
      "    Total DRAM Elapsed Cycles        cycle      363,520\n",
      "    Average L1 Active Cycles         cycle        12.73\n",
      "    Total L1 Elapsed Cycles          cycle      728,312\n",
      "    Average L2 Active Cycles         cycle     1,105.22\n",
      "    Total L2 Elapsed Cycles          cycle      474,000\n",
      "    Average SM Active Cycles         cycle        12.73\n",
      "    Total SM Elapsed Cycles          cycle      728,312\n",
      "    Average SMSP Active Cycles       cycle         8.82\n",
      "    Total SMSP Elapsed Cycles        cycle    2,913,248\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 5.679%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 30.45% above the average, while the minimum instance value is 12.78% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)4, at::native::AUnaryFunctor<float, float, bool, at::native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, (unsigned long)2>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.58\n",
      "    SM Frequency            cycle/nsecond         1.56\n",
      "    Elapsed Cycles                  cycle        5,102\n",
      "    Memory Throughput                   %         9.77\n",
      "    DRAM Throughput                     %         0.04\n",
      "    Duration                      usecond         3.26\n",
      "    L1/TEX Cache Throughput             %        62.86\n",
      "    L2 Cache Throughput                 %        11.12\n",
      "    SM Active Cycles                cycle        11.14\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           21\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.88\n",
      "    Achieved Active Warps Per SM           warp         2.49\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.12%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (3.9%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         3.60\n",
      "    Total DRAM Elapsed Cycles        cycle      337,024\n",
      "    Average L1 Active Cycles         cycle        11.14\n",
      "    Total L1 Elapsed Cycles          cycle      672,918\n",
      "    Average L2 Active Cycles         cycle     1,105.24\n",
      "    Total L2 Elapsed Cycles          cycle      437,840\n",
      "    Average SM Active Cycles         cycle        11.14\n",
      "    Total SM Elapsed Cycles          cycle      672,918\n",
      "    Average SMSP Active Cycles       cycle         6.43\n",
      "    Total SMSP Elapsed Cycles        cycle    2,691,672\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 6.845%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 33.90% above the average, while the minimum instance value is 11.69% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<bool, bool, bool, at::native::BitwiseAndFunctor<bool>>, std::array<char *, (unsigned long)3>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.59\n",
      "    SM Frequency            cycle/nsecond         1.57\n",
      "    Elapsed Cycles                  cycle        5,430\n",
      "    Memory Throughput                   %         9.16\n",
      "    DRAM Throughput                     %         0.07\n",
      "    Duration                      usecond         3.46\n",
      "    L1/TEX Cache Throughput             %        53.01\n",
      "    L2 Cache Throughput                 %        10.42\n",
      "    SM Active Cycles                cycle        13.20\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              30\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           16\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         4.26\n",
      "    Achieved Active Warps Per SM           warp         2.73\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 95.74%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (4.3%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle            6\n",
      "    Total DRAM Elapsed Cycles        cycle      358,016\n",
      "    Average L1 Active Cycles         cycle        13.20\n",
      "    Total L1 Elapsed Cycles          cycle      714,794\n",
      "    Average L2 Active Cycles         cycle     1,096.92\n",
      "    Total L2 Elapsed Cycles          cycle      466,960\n",
      "    Average SM Active Cycles         cycle        13.20\n",
      "    Total SM Elapsed Cycles          cycle      714,794\n",
      "    Average SMSP Active Cycles       cycle         7.05\n",
      "    Total SMSP Elapsed Cycles        cycle    2,859,176\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 6.337%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 33.72% above the average, while the minimum instance value is 12.57% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at_cuda_detail::cub::DeviceReduceSingleTileKernel<at_cuda_detail::cub::DeviceReducePolicy<int, unsigned long long, cuda::std::__4::plus<void>>::Policy600, at_cuda_detail::cub::TransformInputIterator<bool, at::native::<unnamed>::NonZeroOp<bool>, const bool *, long>, int *, unsigned long long, cuda::std::__4::plus<void>, int, int>(T2, T3, T4, T5, T6) (1, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.58\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        5,542\n",
      "    Memory Throughput                   %         9.08\n",
      "    DRAM Throughput                     %         0.12\n",
      "    Duration                      usecond         3.49\n",
      "    L1/TEX Cache Throughput             %        39.49\n",
      "    L2 Cache Throughput                 %        10.40\n",
      "    SM Active Cycles                cycle        17.73\n",
      "    Compute (SM) Throughput             %         0.02\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   256\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              29\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block              44\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             256\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block            8\n",
      "    Block Limit Shared Mem                block           28\n",
      "    Block Limit Warps                     block            8\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        11.70\n",
      "    Achieved Active Warps Per SM           warp         7.49\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 88.3%                                                                                     \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.7%) can be the     \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle        10.40\n",
      "    Total DRAM Elapsed Cycles        cycle      360,192\n",
      "    Average L1 Active Cycles         cycle        17.73\n",
      "    Total L1 Elapsed Cycles          cycle      730,902\n",
      "    Average L2 Active Cycles         cycle     1,091.36\n",
      "    Total L2 Elapsed Cycles          cycle      471,440\n",
      "    Average SM Active Cycles         cycle        17.73\n",
      "    Total SM Elapsed Cycles          cycle      730,902\n",
      "    Average SMSP Active Cycles       cycle        14.07\n",
      "    Total SMSP Elapsed Cycles        cycle    2,923,608\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 6.56%                                                                                           \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 35.42% above the average, while the minimum instance value is 11.49% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, (bool)1>, int *>(T1, int, T2) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.56\n",
      "    SM Frequency            cycle/nsecond         1.57\n",
      "    Elapsed Cycles                  cycle        4,477\n",
      "    Memory Throughput                   %        11.25\n",
      "    DRAM Throughput                     %         0.03\n",
      "    Duration                      usecond         2.85\n",
      "    L1/TEX Cache Throughput             %        91.39\n",
      "    L2 Cache Throughput                 %        12.77\n",
      "    SM Active Cycles                cycle         7.66\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           32\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         5.73\n",
      "    Achieved Active Warps Per SM           warp         3.67\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 94.27%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (5.7%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         2.40\n",
      "    Total DRAM Elapsed Cycles        cycle      291,840\n",
      "    Average L1 Active Cycles         cycle         7.66\n",
      "    Total L1 Elapsed Cycles          cycle      590,346\n",
      "    Average L2 Active Cycles         cycle     1,095.49\n",
      "    Total L2 Elapsed Cycles          cycle      380,480\n",
      "    Average SM Active Cycles         cycle         7.66\n",
      "    Total SM Elapsed Cycles          cycle      590,346\n",
      "    Average SMSP Active Cycles       cycle         6.87\n",
      "    Total SMSP Elapsed Cycles        cycle    2,361,384\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 8.77%                                                                                           \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 38.07% above the average, while the minimum instance value is 13.28% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at_cuda_detail::cub::DeviceSelectSweepKernel<at_cuda_detail::cub::detail::device_select_policy_hub<long, bool, int, (bool)0, (bool)0>::Policy900, at_cuda_detail::cub::CountingInputIterator<long, long>, at_cuda_detail::cub::TransformInputIterator<bool, at::native::<unnamed>::NonZeroOp<bool>, const bool *, long>, long *, int *, at_cuda_detail::cub::ScanTileState<int, (bool)1>, at_cuda_detail::cub::NullType, at_cuda_detail::cub::NullType, int, (bool)0>(T2, T3, T4, T5, T6, T7, T8, T9, int) (1, 1, 1)x(384, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.60\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        6,114\n",
      "    Memory Throughput                   %         8.24\n",
      "    DRAM Throughput                     %         0.31\n",
      "    Duration                      usecond         3.84\n",
      "    L1/TEX Cache Throughput             %        37.24\n",
      "    L2 Cache Throughput                 %         9.31\n",
      "    SM Active Cycles                cycle        18.80\n",
      "    Compute (SM) Throughput             %         0.11\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   384\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              40\n",
      "    Shared Memory Configuration Size           Kbyte          167.94\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block       Kbyte/block           33.79\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             384\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block            4\n",
      "    Block Limit Warps                     block            5\n",
      "    Theoretical Active Warps per SM        warp           48\n",
      "    Theoretical Occupancy                     %           75\n",
      "    Achieved Occupancy                        %        18.06\n",
      "    Achieved Active Warps Per SM           warp        11.56\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 75.92%                                                                                    \n",
      "          The difference between calculated theoretical (75.0%) and measured achieved occupancy (18.1%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    OPT   Est. Local Speedup: 25%                                                                                       \n",
      "          The 12.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the      \n",
      "          hardware maximum of 16. This kernel's theoretical occupancy (75.0%) is limited by the number of required      \n",
      "          registers. This kernel's theoretical occupancy (75.0%) is limited by the required amount of shared memory.    \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle        31.40\n",
      "    Total DRAM Elapsed Cycles        cycle      398,848\n",
      "    Average L1 Active Cycles         cycle        18.80\n",
      "    Total L1 Elapsed Cycles          cycle      806,572\n",
      "    Average L2 Active Cycles         cycle     1,109.70\n",
      "    Total L2 Elapsed Cycles          cycle      519,680\n",
      "    Average SM Active Cycles         cycle        18.80\n",
      "    Total SM Elapsed Cycles          cycle      806,572\n",
      "    Average SMSP Active Cycles       cycle        18.34\n",
      "    Total SMSP Elapsed Cycles        cycle    3,226,288\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 5.925%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 34.69% above the average, while the minimum instance value is 12.77% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::index_elementwise_kernel<(int)128, (int)4, void at::native::gpu_index_kernel<void at::native::index_kernel_impl<at::native::OpaqueType<(int)4>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.57\n",
      "    SM Frequency            cycle/nsecond         1.58\n",
      "    Elapsed Cycles                  cycle        7,194\n",
      "    Memory Throughput                   %         6.99\n",
      "    DRAM Throughput                     %         0.32\n",
      "    Duration                      usecond         4.54\n",
      "    L1/TEX Cache Throughput             %        29.37\n",
      "    L2 Cache Throughput                 %         7.95\n",
      "    SM Active Cycles                cycle        23.83\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              40\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           12\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           48\n",
      "    Theoretical Occupancy                     %           75\n",
      "    Achieved Occupancy                        %         2.28\n",
      "    Achieved Active Warps Per SM           warp         1.46\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.96%                                                                                    \n",
      "          The difference between calculated theoretical (75.0%) and measured achieved occupancy (2.3%) can be the       \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    OPT   Est. Local Speedup: 25%                                                                                       \n",
      "          The 12.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the      \n",
      "          hardware maximum of 16. This kernel's theoretical occupancy (75.0%) is limited by the number of required      \n",
      "          registers.                                                                                                    \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle        37.40\n",
      "    Total DRAM Elapsed Cycles        cycle      467,968\n",
      "    Average L1 Active Cycles         cycle        23.83\n",
      "    Total L1 Elapsed Cycles          cycle      949,290\n",
      "    Average L2 Active Cycles         cycle     1,138.29\n",
      "    Total L2 Elapsed Cycles          cycle      612,640\n",
      "    Average SM Active Cycles         cycle        23.83\n",
      "    Total SM Elapsed Cycles          cycle      949,290\n",
      "    Average SMSP Active Cycles       cycle         8.39\n",
      "    Total SMSP Elapsed Cycles        cycle    3,797,160\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 6.319%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 42.51% above the average, while the minimum instance value is 14.52% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)4, at::native::AbsFunctor<float>, std::array<char *, (unsigned long)2>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.61\n",
      "    SM Frequency            cycle/nsecond         1.60\n",
      "    Elapsed Cycles                  cycle        4,975\n",
      "    Memory Throughput                   %        10.12\n",
      "    DRAM Throughput                     %         0.04\n",
      "    Duration                      usecond         3.10\n",
      "    L1/TEX Cache Throughput             %        61.07\n",
      "    L2 Cache Throughput                 %        11.55\n",
      "    SM Active Cycles                cycle        11.46\n",
      "    Compute (SM) Throughput             %         0.00\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           32\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.92\n",
      "    Achieved Active Warps Per SM           warp         2.51\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.08%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (3.9%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle            3\n",
      "    Total DRAM Elapsed Cycles        cycle      324,096\n",
      "    Average L1 Active Cycles         cycle        11.46\n",
      "    Total L1 Elapsed Cycles          cycle      656,310\n",
      "    Average L2 Active Cycles         cycle     1,091.46\n",
      "    Total L2 Elapsed Cycles          cycle      422,960\n",
      "    Average SM Active Cycles         cycle        11.46\n",
      "    Total SM Elapsed Cycles          cycle      656,310\n",
      "    Average SMSP Active Cycles       cycle         7.42\n",
      "    Total SMSP Elapsed Cycles        cycle    2,625,240\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 7.005%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 33.93% above the average, while the minimum instance value is 11.04% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(double) (instance 1)], std::array<char *, (unsigned long)2>, (int)4, TrivialOffsetCalculator<(int)1, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithCast<(int)1>, at::native::memory::StoreWithCast<(int)1>>(int, T1, T2, T4, T5, T6, T7) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.58\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        4,978\n",
      "    Memory Throughput                   %        10.11\n",
      "    DRAM Throughput                     %         0.30\n",
      "    Duration                      usecond         3.14\n",
      "    L1/TEX Cache Throughput             %        59.92\n",
      "    L2 Cache Throughput                 %        11.37\n",
      "    SM Active Cycles                cycle        11.68\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              42\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           10\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           40\n",
      "    Theoretical Occupancy                     %        62.50\n",
      "    Achieved Occupancy                        %         3.42\n",
      "    Achieved Active Warps Per SM           warp         2.19\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 94.53%                                                                                    \n",
      "          The difference between calculated theoretical (62.5%) and measured achieved occupancy (3.4%) can be the       \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    OPT   Est. Local Speedup: 37.5%                                                                                     \n",
      "          The 10.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the      \n",
      "          hardware maximum of 16. This kernel's theoretical occupancy (62.5%) is limited by the number of required      \n",
      "          registers.                                                                                                    \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle        24.60\n",
      "    Total DRAM Elapsed Cycles        cycle      323,072\n",
      "    Average L1 Active Cycles         cycle        11.68\n",
      "    Total L1 Elapsed Cycles          cycle      656,848\n",
      "    Average L2 Active Cycles         cycle     1,101.36\n",
      "    Total L2 Elapsed Cycles          cycle      423,360\n",
      "    Average SM Active Cycles         cycle        11.68\n",
      "    Total SM Elapsed Cycles          cycle      656,848\n",
      "    Average SMSP Active Cycles       cycle         6.50\n",
      "    Total SMSP Elapsed Cycles        cycle    2,627,392\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 9.521%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 45.75% above the average, while the minimum instance value is 11.56% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<double, at::native::func_wrapper_t<double, at::native::MinNanFunctor<double>>, unsigned int, double, (int)4>>(T3) (1, 1, 1)x(4, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.60\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        8,608\n",
      "    Memory Throughput                   %         5.84\n",
      "    DRAM Throughput                     %         0.37\n",
      "    Duration                      usecond         5.41\n",
      "    L1/TEX Cache Throughput             %        24.38\n",
      "    L2 Cache Throughput                 %         6.72\n",
      "    SM Active Cycles                cycle        28.71\n",
      "    Compute (SM) Throughput             %         0.00\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                     4\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              32\n",
      "    Shared Memory Configuration Size           Kbyte           65.54\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block              16\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread               4\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 87.5%                                                                                           \n",
      "          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      \n",
      "          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       \n",
      "          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      \n",
      "          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      \n",
      "          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     \n",
      "          kernels that frequently call __syncthreads(). See the Hardware Model                                          \n",
      "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      \n",
      "          details on launch configurations.                                                                             \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           64\n",
      "    Block Limit Shared Mem                block           56\n",
      "    Block Limit Warps                     block           64\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %           50\n",
      "    Achieved Occupancy                        %         1.56\n",
      "    Achieved Active Warps Per SM           warp            1\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.88%                                                                                    \n",
      "          The difference between calculated theoretical (50.0%) and measured achieved occupancy (1.6%) can be the       \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    OPT   Est. Local Speedup: 50%                                                                                       \n",
      "          The 8.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       \n",
      "          hardware maximum of 16. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that   \n",
      "          can fit on the SM.                                                                                            \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle        52.40\n",
      "    Total DRAM Elapsed Cycles        cycle      561,920\n",
      "    Average L1 Active Cycles         cycle        28.71\n",
      "    Total L1 Elapsed Cycles          cycle    1,135,814\n",
      "    Average L2 Active Cycles         cycle     1,097.26\n",
      "    Total L2 Elapsed Cycles          cycle      732,640\n",
      "    Average SM Active Cycles         cycle        28.71\n",
      "    Total SM Elapsed Cycles          cycle    1,135,814\n",
      "    Average SMSP Active Cycles       cycle         7.43\n",
      "    Total SMSP Elapsed Cycles        cycle    4,543,256\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "  void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<double, at::native::func_wrapper_t<double, at::native::MaxNanFunctor<double>>, unsigned int, double, (int)4>>(T3) (1, 1, 1)x(4, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.60\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        7,604\n",
      "    Memory Throughput                   %         6.62\n",
      "    DRAM Throughput                     %         0.42\n",
      "    Duration                      usecond         4.77\n",
      "    L1/TEX Cache Throughput             %        28.62\n",
      "    L2 Cache Throughput                 %         7.47\n",
      "    SM Active Cycles                cycle        24.45\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                     4\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              32\n",
      "    Shared Memory Configuration Size           Kbyte           65.54\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block              16\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread               4\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 87.5%                                                                                           \n",
      "          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      \n",
      "          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       \n",
      "          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      \n",
      "          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      \n",
      "          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     \n",
      "          kernels that frequently call __syncthreads(). See the Hardware Model                                          \n",
      "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      \n",
      "          details on launch configurations.                                                                             \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           64\n",
      "    Block Limit Shared Mem                block           56\n",
      "    Block Limit Warps                     block           64\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %           50\n",
      "    Achieved Occupancy                        %         1.56\n",
      "    Achieved Active Warps Per SM           warp            1\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.88%                                                                                    \n",
      "          The difference between calculated theoretical (50.0%) and measured achieved occupancy (1.6%) can be the       \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    OPT   Est. Local Speedup: 50%                                                                                       \n",
      "          The 8.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       \n",
      "          hardware maximum of 16. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that   \n",
      "          can fit on the SM.                                                                                            \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle        52.20\n",
      "    Total DRAM Elapsed Cycles        cycle      496,128\n",
      "    Average L1 Active Cycles         cycle        24.45\n",
      "    Total L1 Elapsed Cycles          cycle    1,003,388\n",
      "    Average L2 Active Cycles         cycle     1,139.35\n",
      "    Total L2 Elapsed Cycles          cycle      646,640\n",
      "    Average SM Active Cycles         cycle        24.45\n",
      "    Total SM Elapsed Cycles          cycle    1,003,388\n",
      "    Average SMSP Active Cycles       cycle         6.10\n",
      "    Total SMSP Elapsed Cycles        cycle    4,013,552\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)4, at::native::ceil_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, (unsigned long)2>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.60\n",
      "    SM Frequency            cycle/nsecond         1.60\n",
      "    Elapsed Cycles                  cycle        5,374\n",
      "    Memory Throughput                   %         9.37\n",
      "    DRAM Throughput                     %         0.03\n",
      "    Duration                      usecond         3.36\n",
      "    L1/TEX Cache Throughput             %        61.64\n",
      "    L2 Cache Throughput                 %        10.65\n",
      "    SM Active Cycles                cycle        11.36\n",
      "    Compute (SM) Throughput             %         0.00\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           21\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.95\n",
      "    Achieved Active Warps Per SM           warp         2.53\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.05%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (3.9%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle            3\n",
      "    Total DRAM Elapsed Cycles        cycle      349,440\n",
      "    Average L1 Active Cycles         cycle        11.36\n",
      "    Total L1 Elapsed Cycles          cycle      708,860\n",
      "    Average L2 Active Cycles         cycle     1,094.74\n",
      "    Total L2 Elapsed Cycles          cycle      456,720\n",
      "    Average SM Active Cycles         cycle        11.36\n",
      "    Total SM Elapsed Cycles          cycle      708,860\n",
      "    Average SMSP Active Cycles       cycle         7.31\n",
      "    Total SMSP Elapsed Cycles        cycle    2,835,440\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 5.788%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 30.18% above the average, while the minimum instance value is 10.85% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<float, float, bool, at::native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, (unsigned long)3>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.60\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        4,982\n",
      "    Memory Throughput                   %        10.11\n",
      "    DRAM Throughput                     %         0.05\n",
      "    Duration                      usecond         3.14\n",
      "    L1/TEX Cache Throughput             %        63.81\n",
      "    L2 Cache Throughput                 %        11.45\n",
      "    SM Active Cycles                cycle        10.97\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              26\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           16\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.80\n",
      "    Achieved Active Warps Per SM           warp         2.43\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.2%                                                                                     \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (3.8%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         3.80\n",
      "    Total DRAM Elapsed Cycles        cycle      325,632\n",
      "    Average L1 Active Cycles         cycle        10.97\n",
      "    Total L1 Elapsed Cycles          cycle      657,246\n",
      "    Average L2 Active Cycles         cycle     1,110.16\n",
      "    Total L2 Elapsed Cycles          cycle      423,360\n",
      "    Average SM Active Cycles         cycle        10.97\n",
      "    Total SM Elapsed Cycles          cycle      657,246\n",
      "    Average SMSP Active Cycles       cycle         7.78\n",
      "    Total SMSP Elapsed Cycles        cycle    2,628,984\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 9.689%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 46.19% above the average, while the minimum instance value is 13.08% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::unrolled_elementwise_kernel<at::native::ceil_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, (unsigned long)2>, (int)4, TrivialOffsetCalculator<(int)1, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.58\n",
      "    SM Frequency            cycle/nsecond         1.58\n",
      "    Elapsed Cycles                  cycle        4,815\n",
      "    Memory Throughput                   %        10.45\n",
      "    DRAM Throughput                     %         0.03\n",
      "    Duration                      usecond         3.04\n",
      "    L1/TEX Cache Throughput             %        71.52\n",
      "    L2 Cache Throughput                 %        11.87\n",
      "    SM Active Cycles                cycle         9.79\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           21\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.83\n",
      "    Achieved Active Warps Per SM           warp         2.45\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.17%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (3.8%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         2.60\n",
      "    Total DRAM Elapsed Cycles        cycle      314,112\n",
      "    Average L1 Active Cycles         cycle         9.79\n",
      "    Total L1 Elapsed Cycles          cycle      634,980\n",
      "    Average L2 Active Cycles         cycle     1,099.69\n",
      "    Total L2 Elapsed Cycles          cycle      409,280\n",
      "    Average SM Active Cycles         cycle         9.79\n",
      "    Total SM Elapsed Cycles          cycle      634,980\n",
      "    Average SMSP Active Cycles       cycle         5.73\n",
      "    Total SMSP Elapsed Cycles        cycle    2,539,920\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 6.777%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 31.53% above the average, while the minimum instance value is 12.70% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<float, float, bool, at::native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, (unsigned long)3>, (int)4, TrivialOffsetCalculator<(int)2, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.57\n",
      "    SM Frequency            cycle/nsecond         1.57\n",
      "    Elapsed Cycles                  cycle        4,787\n",
      "    Memory Throughput                   %        10.51\n",
      "    DRAM Throughput                     %         0.04\n",
      "    Duration                      usecond         3.04\n",
      "    L1/TEX Cache Throughput             %        55.80\n",
      "    L2 Cache Throughput                 %        11.97\n",
      "    SM Active Cycles                cycle        12.55\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              26\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           16\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         4.33\n",
      "    Achieved Active Warps Per SM           warp         2.77\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 95.67%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (4.3%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         3.20\n",
      "    Total DRAM Elapsed Cycles        cycle      312,320\n",
      "    Average L1 Active Cycles         cycle        12.55\n",
      "    Total L1 Elapsed Cycles          cycle      631,438\n",
      "    Average L2 Active Cycles         cycle     1,107.62\n",
      "    Total L2 Elapsed Cycles          cycle      407,200\n",
      "    Average SM Active Cycles         cycle        12.55\n",
      "    Total SM Elapsed Cycles          cycle      631,438\n",
      "    Average SMSP Active Cycles       cycle         6.31\n",
      "    Total SMSP Elapsed Cycles        cycle    2,525,752\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 6.965%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 32.01% above the average, while the minimum instance value is 12.43% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)2, at::native::ceil_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, (unsigned long)2>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.59\n",
      "    SM Frequency            cycle/nsecond         1.58\n",
      "    Elapsed Cycles                  cycle        4,904\n",
      "    Memory Throughput                   %        10.26\n",
      "    DRAM Throughput                     %         0.04\n",
      "    Duration                      usecond         3.10\n",
      "    L1/TEX Cache Throughput             %        56.55\n",
      "    L2 Cache Throughput                 %        11.73\n",
      "    SM Active Cycles                cycle        12.38\n",
      "    Compute (SM) Throughput             %         0.00\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           21\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.82\n",
      "    Achieved Active Warps Per SM           warp         2.45\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.18%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (3.8%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         3.20\n",
      "    Total DRAM Elapsed Cycles        cycle      321,280\n",
      "    Average L1 Active Cycles         cycle        12.38\n",
      "    Total L1 Elapsed Cycles          cycle      647,178\n",
      "    Average L2 Active Cycles         cycle     1,092.11\n",
      "    Total L2 Elapsed Cycles          cycle      417,120\n",
      "    Average SM Active Cycles         cycle        12.38\n",
      "    Total SM Elapsed Cycles          cycle      647,178\n",
      "    Average SMSP Active Cycles       cycle         7.33\n",
      "    Total SMSP Elapsed Cycles        cycle    2,588,712\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 5.877%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 28.06% above the average, while the minimum instance value is 11.64% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)2, at::native::BinaryFunctor<float, float, bool, at::native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, (unsigned long)3>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.59\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        4,890\n",
      "    Memory Throughput                   %        10.29\n",
      "    DRAM Throughput                     %         0.05\n",
      "    Duration                      usecond         3.07\n",
      "    L1/TEX Cache Throughput             %        56.93\n",
      "    L2 Cache Throughput                 %        11.74\n",
      "    SM Active Cycles                cycle        12.30\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              26\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           16\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         4.11\n",
      "    Achieved Active Warps Per SM           warp         2.63\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 95.89%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (4.1%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         3.80\n",
      "    Total DRAM Elapsed Cycles        cycle      317,696\n",
      "    Average L1 Active Cycles         cycle        12.30\n",
      "    Total L1 Elapsed Cycles          cycle      645,168\n",
      "    Average L2 Active Cycles         cycle     1,102.61\n",
      "    Total L2 Elapsed Cycles          cycle      415,680\n",
      "    Average SM Active Cycles         cycle        12.30\n",
      "    Total SM Elapsed Cycles          cycle      645,168\n",
      "    Average SMSP Active Cycles       cycle         8.49\n",
      "    Total SMSP Elapsed Cycles        cycle    2,580,672\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 6.962%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 32.81% above the average, while the minimum instance value is 13.30% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::unrolled_elementwise_kernel<at::native::ceil_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, (unsigned long)2>, (int)4, TrivialOffsetCalculator<(int)1, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.59\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        4,928\n",
      "    Memory Throughput                   %        10.21\n",
      "    DRAM Throughput                     %         0.03\n",
      "    Duration                      usecond         3.10\n",
      "    L1/TEX Cache Throughput             %        64.71\n",
      "    L2 Cache Throughput                 %        11.58\n",
      "    SM Active Cycles                cycle        10.82\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           21\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         4.10\n",
      "    Achieved Active Warps Per SM           warp         2.62\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 95.9%                                                                                     \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (4.1%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         2.80\n",
      "    Total DRAM Elapsed Cycles        cycle      321,536\n",
      "    Average L1 Active Cycles         cycle        10.82\n",
      "    Total L1 Elapsed Cycles          cycle      650,134\n",
      "    Average L2 Active Cycles         cycle     1,091.74\n",
      "    Total L2 Elapsed Cycles          cycle      419,280\n",
      "    Average SM Active Cycles         cycle        10.82\n",
      "    Total SM Elapsed Cycles          cycle      650,134\n",
      "    Average SMSP Active Cycles       cycle         8.83\n",
      "    Total SMSP Elapsed Cycles        cycle    2,600,536\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 5.996%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 28.78% above the average, while the minimum instance value is 12.43% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<float, float, bool, at::native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, (unsigned long)3>, (int)4, TrivialOffsetCalculator<(int)2, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.60\n",
      "    SM Frequency            cycle/nsecond         1.60\n",
      "    Elapsed Cycles                  cycle        4,966\n",
      "    Memory Throughput                   %        10.13\n",
      "    DRAM Throughput                     %         0.04\n",
      "    Duration                      usecond         3.10\n",
      "    L1/TEX Cache Throughput             %        64.62\n",
      "    L2 Cache Throughput                 %        11.56\n",
      "    SM Active Cycles                cycle        10.83\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              26\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           16\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.73\n",
      "    Achieved Active Warps Per SM           warp         2.39\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.27%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (3.7%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         3.40\n",
      "    Total DRAM Elapsed Cycles        cycle      322,560\n",
      "    Average L1 Active Cycles         cycle        10.83\n",
      "    Total L1 Elapsed Cycles          cycle      655,162\n",
      "    Average L2 Active Cycles         cycle     1,097.79\n",
      "    Total L2 Elapsed Cycles          cycle      422,320\n",
      "    Average SM Active Cycles         cycle        10.83\n",
      "    Total SM Elapsed Cycles          cycle      655,162\n",
      "    Average SMSP Active Cycles       cycle         7.40\n",
      "    Total SMSP Elapsed Cycles        cycle    2,620,648\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 6.738%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 32.40% above the average, while the minimum instance value is 13.37% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)4, at::native::ceil_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, (unsigned long)2>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.59\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        5,035\n",
      "    Memory Throughput                   %        10.00\n",
      "    DRAM Throughput                     %         0.04\n",
      "    Duration                      usecond         3.17\n",
      "    L1/TEX Cache Throughput             %        67.40\n",
      "    L2 Cache Throughput                 %        11.38\n",
      "    SM Active Cycles                cycle        10.39\n",
      "    Compute (SM) Throughput             %         0.00\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           21\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.74\n",
      "    Achieved Active Warps Per SM           warp         2.39\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.26%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (3.7%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle            3\n",
      "    Total DRAM Elapsed Cycles        cycle      327,680\n",
      "    Average L1 Active Cycles         cycle        10.39\n",
      "    Total L1 Elapsed Cycles          cycle      664,206\n",
      "    Average L2 Active Cycles         cycle     1,101.36\n",
      "    Total L2 Elapsed Cycles          cycle      428,000\n",
      "    Average SM Active Cycles         cycle        10.39\n",
      "    Total SM Elapsed Cycles          cycle      664,206\n",
      "    Average SMSP Active Cycles       cycle         6.01\n",
      "    Total SMSP Elapsed Cycles        cycle    2,656,824\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 6.089%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 29.58% above the average, while the minimum instance value is 12.29% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<float, float, bool, at::native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, (unsigned long)3>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.60\n",
      "    SM Frequency            cycle/nsecond         1.60\n",
      "    Elapsed Cycles                  cycle        5,008\n",
      "    Memory Throughput                   %        10.05\n",
      "    DRAM Throughput                     %         0.05\n",
      "    Duration                      usecond         3.14\n",
      "    L1/TEX Cache Throughput             %        53.44\n",
      "    L2 Cache Throughput                 %        11.48\n",
      "    SM Active Cycles                cycle        13.10\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              26\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           16\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.49\n",
      "    Achieved Active Warps Per SM           warp         2.23\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.51%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (3.5%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         3.80\n",
      "    Total DRAM Elapsed Cycles        cycle      325,632\n",
      "    Average L1 Active Cycles         cycle        13.10\n",
      "    Total L1 Elapsed Cycles          cycle      660,762\n",
      "    Average L2 Active Cycles         cycle     1,109.67\n",
      "    Total L2 Elapsed Cycles          cycle      426,000\n",
      "    Average SM Active Cycles         cycle        13.10\n",
      "    Total SM Elapsed Cycles          cycle      660,762\n",
      "    Average SMSP Active Cycles       cycle         7.57\n",
      "    Total SMSP Elapsed Cycles        cycle    2,643,048\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 6.773%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 32.50% above the average, while the minimum instance value is 13.76% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::unrolled_elementwise_kernel<at::native::ceil_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, (unsigned long)2>, (int)4, TrivialOffsetCalculator<(int)1, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.61\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        4,746\n",
      "    Memory Throughput                   %        10.61\n",
      "    DRAM Throughput                     %         0.04\n",
      "    Duration                      usecond         2.98\n",
      "    L1/TEX Cache Throughput             %        63.51\n",
      "    L2 Cache Throughput                 %        12.04\n",
      "    SM Active Cycles                cycle        11.02\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              18\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           21\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         3.52\n",
      "    Achieved Active Warps Per SM           warp         2.26\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 96.48%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (3.5%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle            3\n",
      "    Total DRAM Elapsed Cycles        cycle      310,912\n",
      "    Average L1 Active Cycles         cycle        11.02\n",
      "    Total L1 Elapsed Cycles          cycle      625,980\n",
      "    Average L2 Active Cycles         cycle     1,100.92\n",
      "    Total L2 Elapsed Cycles          cycle      403,360\n",
      "    Average SM Active Cycles         cycle        11.02\n",
      "    Total SM Elapsed Cycles          cycle      625,980\n",
      "    Average SMSP Active Cycles       cycle         5.87\n",
      "    Total SMSP Elapsed Cycles        cycle    2,503,920\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 6.773%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 31.02% above the average, while the minimum instance value is 11.80% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<float, float, bool, at::native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, (unsigned long)3>, (int)4, TrivialOffsetCalculator<(int)2, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.59\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        5,028\n",
      "    Memory Throughput                   %        10.01\n",
      "    DRAM Throughput                     %         0.04\n",
      "    Duration                      usecond         3.17\n",
      "    L1/TEX Cache Throughput             %        60.95\n",
      "    L2 Cache Throughput                 %        11.45\n",
      "    SM Active Cycles                cycle        11.48\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              26\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           16\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         4.12\n",
      "    Achieved Active Warps Per SM           warp         2.64\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 95.88%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (4.1%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         3.20\n",
      "    Total DRAM Elapsed Cycles        cycle      327,680\n",
      "    Average L1 Active Cycles         cycle        11.48\n",
      "    Total L1 Elapsed Cycles          cycle      663,378\n",
      "    Average L2 Active Cycles         cycle     1,117.64\n",
      "    Total L2 Elapsed Cycles          cycle      427,520\n",
      "    Average SM Active Cycles         cycle        11.48\n",
      "    Total SM Elapsed Cycles          cycle      663,378\n",
      "    Average SMSP Active Cycles       cycle         6.50\n",
      "    Total SMSP Elapsed Cycles        cycle    2,653,512\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 8.127%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 38.86% above the average, while the minimum instance value is 15.18% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<double, double, double, at::native::binary_internal::DivFunctor<double>>, std::array<char *, (unsigned long)3>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.58\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        5,229\n",
      "    Memory Throughput                   %         9.63\n",
      "    DRAM Throughput                     %         0.08\n",
      "    Duration                      usecond         3.30\n",
      "    L1/TEX Cache Throughput             %        54.55\n",
      "    L2 Cache Throughput                 %        10.99\n",
      "    SM Active Cycles                cycle        12.83\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              44\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           10\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           40\n",
      "    Theoretical Occupancy                     %        62.50\n",
      "    Achieved Occupancy                        %         3.81\n",
      "    Achieved Active Warps Per SM           warp         2.44\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 93.91%                                                                                    \n",
      "          The difference between calculated theoretical (62.5%) and measured achieved occupancy (3.8%) can be the       \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    OPT   Est. Local Speedup: 37.5%                                                                                     \n",
      "          The 10.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the      \n",
      "          hardware maximum of 16. This kernel's theoretical occupancy (62.5%) is limited by the number of required      \n",
      "          registers.                                                                                                    \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         6.80\n",
      "    Total DRAM Elapsed Cycles        cycle      339,968\n",
      "    Average L1 Active Cycles         cycle        12.83\n",
      "    Total L1 Elapsed Cycles          cycle      689,918\n",
      "    Average L2 Active Cycles         cycle     1,108.25\n",
      "    Total L2 Elapsed Cycles          cycle      444,400\n",
      "    Average SM Active Cycles         cycle        12.83\n",
      "    Total SM Elapsed Cycles          cycle      689,918\n",
      "    Average SMSP Active Cycles       cycle         9.14\n",
      "    Total SMSP Elapsed Cycles        cycle    2,759,672\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 5.786%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 29.00% above the average, while the minimum instance value is 13.38% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)4, void at::native::compare_scalar_kernel<double>(at::TensorIteratorBase &, at::native::<unnamed>::OpType, T1)::[lambda(double) (instance 1)], std::array<char *, (unsigned long)2>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.59\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        5,043\n",
      "    Memory Throughput                   %         9.98\n",
      "    DRAM Throughput                     %         0.05\n",
      "    Duration                      usecond         3.17\n",
      "    L1/TEX Cache Throughput             %        56.93\n",
      "    L2 Cache Throughput                 %        11.35\n",
      "    SM Active Cycles                cycle        12.30\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              20\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           21\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         4.69\n",
      "    Achieved Active Warps Per SM           warp         3.00\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 95.31%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (4.7%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         4.40\n",
      "    Total DRAM Elapsed Cycles        cycle      328,192\n",
      "    Average L1 Active Cycles         cycle        12.30\n",
      "    Total L1 Elapsed Cycles          cycle      665,396\n",
      "    Average L2 Active Cycles         cycle     1,088.99\n",
      "    Total L2 Elapsed Cycles          cycle      428,880\n",
      "    Average SM Active Cycles         cycle        12.30\n",
      "    Total SM Elapsed Cycles          cycle      665,396\n",
      "    Average SMSP Active Cycles       cycle         7.65\n",
      "    Total SMSP Elapsed Cycles        cycle    2,661,584\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 6.675%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 32.86% above the average, while the minimum instance value is 11.57% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "  void at::native::vectorized_elementwise_kernel<(int)4, void at::native::compare_scalar_kernel<double>(at::TensorIteratorBase &, at::native::<unnamed>::OpType, T1)::[lambda(double) (instance 1)], std::array<char *, (unsigned long)2>>(int, T2, T3) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ------------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ----------------------- ------------- ------------\n",
      "    DRAM Frequency          cycle/nsecond         2.59\n",
      "    SM Frequency            cycle/nsecond         1.59\n",
      "    Elapsed Cycles                  cycle        5,134\n",
      "    Memory Throughput                   %         9.80\n",
      "    DRAM Throughput                     %         0.06\n",
      "    Duration                      usecond         3.23\n",
      "    L1/TEX Cache Throughput             %        65.81\n",
      "    L2 Cache Throughput                 %        11.29\n",
      "    SM Active Cycles                cycle        10.64\n",
      "    Compute (SM) Throughput             %         0.01\n",
      "    ----------------------- ------------- ------------\n",
      "\n",
      "    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
      "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   128\n",
      "    Cluster Scheduling Policy                           PolicySpread\n",
      "    Cluster Size                                                   0\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                      1\n",
      "    Registers Per Thread             register/thread              20\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block       Kbyte/block            1.02\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM             132\n",
      "    Threads                                   thread             128\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                0.00\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    OPT   Est. Speedup: 99.24%                                                                                          \n",
      "          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 132             \n",
      "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
      "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
      "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
      "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
      "          description for more details on launch configurations.                                                        \n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Max Active Clusters                 cluster            0\n",
      "    Max Cluster Size                      block            8\n",
      "    Overall GPU Occupancy                     %            0\n",
      "    Cluster Occupancy                         %            0\n",
      "    Block Limit SM                        block           32\n",
      "    Block Limit Registers                 block           21\n",
      "    Block Limit Shared Mem                block           32\n",
      "    Block Limit Warps                     block           16\n",
      "    Theoretical Active Warps per SM        warp           64\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %         4.67\n",
      "    Achieved Active Warps Per SM           warp         2.99\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 95.33%                                                                                    \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (4.7%) can be the      \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle         4.60\n",
      "    Total DRAM Elapsed Cycles        cycle      334,336\n",
      "    Average L1 Active Cycles         cycle        10.64\n",
      "    Total L1 Elapsed Cycles          cycle      677,292\n",
      "    Average L2 Active Cycles         cycle     1,091.99\n",
      "    Total L2 Elapsed Cycles          cycle      436,480\n",
      "    Average SM Active Cycles         cycle        10.64\n",
      "    Total SM Elapsed Cycles          cycle      677,292\n",
      "    Average SMSP Active Cycles       cycle         9.05\n",
      "    Total SMSP Elapsed Cycles        cycle    2,709,168\n",
      "    -------------------------- ----------- ------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ncu --target-processes all python load_inline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alex/miniforge3/envs/gpum/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "[[ 1.  4.  9.]\n",
      " [16. 25. 36.]]\n"
     ]
    }
   ],
   "source": [
    "!python numba_square.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2 - Triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!code triton_square.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!code square_kernel.ptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] Output code: \n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # AOT ID: ['0_inference']\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import torch\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import math\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import random\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import os\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import tempfile\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from math import inf, nan\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.utils import maybe_profile\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch import device, empty_strided\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid,\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     split_scan_grid,\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid_combo_kernels,\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     start_graph,\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     end_graph,\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     cooperative_reduction_grid,\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] \n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] aten = torch.ops.aten\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] inductor_ops = torch.ops.inductor\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] _quantized = torch.ops._quantized\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile = AsyncCompile()\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] \n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] \n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_alex/2w/c2wd2u7o4dmf6phcx2slilezsusa5akssj27vacmppmvfyqf5fqv.py\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [square], Original ATen: [aten.pow]\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   square => pow_1\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %pow_1 : [num_users=1] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%arg0_1, 2), kwargs = {})\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_pow_0 = async_compile.triton('triton_poi_fused_pow_0', '''\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] \n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] \n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16}, \n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_pow_0', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '9DCB932EF217650ABAB636BFB7B75C0464066E10820E4CB71C69D98802C3B71B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_pow_0(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0), xmask)\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0 * tmp0\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp1, xmask)\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] \n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] \n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile.wait(globals())\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] del async_compile\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] \n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def call(args):\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg0_1, = args\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     args.clear()\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg0_1, (4, 4), (4, 1))\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     with torch.cuda._DeviceGuard(0):\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         torch.cuda.set_device(0)\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf0 = empty_strided_cuda((4, 4), (4, 1), torch.float32)\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [square], Original ATen: [aten.pow]\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_pow_0.run(arg0_1, buf0, 16, grid=grid(16), stream=stream0)\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg0_1\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return (buf0, )\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] \n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] \n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.utils import print_performance\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg0_1 = rand_strided((4, 4), (4, 1), device='cuda:0', dtype=torch.float32)\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     fn = lambda: call([arg0_1])\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] \n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] \n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] if __name__ == \"__main__\":\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)\n",
      "V0218 13:13:36.929000 13100 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] \n",
      "V0218 13:13:36.930000 13100 site-packages/torch/_inductor/graph.py:2053] [0/0] [__output_code] Output code written to: /tmp/torchinductor_alex/ao/caohsffuib2kl5aruonkezo65huexb7usj2gvldl54akjckroxrd.py\n",
      "I0218 13:13:36.992000 13100 site-packages/torch/_inductor/graph.py:2087] [0/0] [__output_code] Output code written to: /tmp/torchinductor_alex/ao/caohsffuib2kl5aruonkezo65huexb7usj2gvldl54akjckroxrd.py\n",
      "tensor([[1.7757e+00, 6.8822e-01, 7.0449e+00, 4.0276e-04],\n",
      "        [4.7556e+00, 3.7629e-01, 1.9361e+00, 7.5063e-01],\n",
      "        [1.6627e+00, 3.3556e-01, 9.5927e-01, 2.5700e-01],\n",
      "        [7.0848e+00, 9.5112e-02, 6.8074e-01, 3.2857e-01]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "!TORCH_LOGS=output_code python ax_pytorch2triton.py # TORCH_LOGS=help python -c \"import torch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 - CUDA Profilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==PROF== Connected to process 13212 (/home/alex/miniforge3/envs/gpum/bin/python3.10)\n",
      "==WARNING== Unable to access the following 6 metrics: ctc__rx_bytes_data_user.sum, ctc__rx_bytes_data_user.sum.pct_of_peak_sustained_elapsed, ctc__rx_bytes_data_user.sum.per_second, ctc__tx_bytes_data_user.sum, ctc__tx_bytes_data_user.sum.pct_of_peak_sustained_elapsed, ctc__tx_bytes_data_user.sum.per_second.\n",
      "\n",
      "==PROF== Profiling \"distribution_elementwise_grid...\" - 0: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"square_kernel\" - 1: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 2: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 3: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 4: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 5: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 6: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 7: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 8: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 9: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 10: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 11: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 12: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 13: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 14: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 15: 0%....50%....100% - 37 passes\n",
      "==PROF== Profiling \"reduce_kernel\" - 16: 0%....50%....100% - 37 passes\n",
      "==PROF== Disconnected from process 13212\n",
      "==PROF== Report: /home/alex/ci/gpum/l_001/lecture_001/output.ncu-rep\n"
     ]
    }
   ],
   "source": [
    "!ncu --set full -o ax_train $(which python) ax_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon obtaining the profiling results, we can open the Nsight app to quickly inspect them in a visual manner.\n",
    "\n",
    "    -> Check the performance oportunities discovered\n",
    "         - Tail effect + achieved occupacy -< often controlled by things like Padding >- We can control Padding \n",
    "         - Long scoreboard stalls -<memory coalescing, use shared memory >- We can't control (Triton does it for us)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
